\documentclass{amsart}

\input{decls}
\input{macros}
\setcounter{tocdepth}{1}
\usepackage[utf8]{inputenc}

\title{Semantics of Higher Inductive Types}

\author{Peter LeFanu Lumsdaine}
\author{Michael Shulman}

\begin{document}

\maketitle

\begin{abstract}
The now-standard homotopy-theoretic models of Voevodsky, Awodey--Warren, et al, show that dependent type theory is expressive enough to talk about homotopy-theoretic properties and constructions.
%
However, traditional type theory provides no way to \emph{construct} homotopically non-trivial types.
Voevodsky's Univalence Axiom goes some way in this direction by ensuring that the universe is homotopically non-trivial, but there is a limit to the additional homotopy types that can be constructed from this.

Higher Inductive Types (HITs) were introduced to remedy this gap (in conjunction with the Univalence Axiom).
%
They generalise ordinary inductive definitions, allowing constructors to produce not only points but \emph{paths} in the posited type.
However, they are also of interest in the absence of Univalence, because they provide well-behaved quotients and free-algebra constructions.

Here we show that many homotopy-theoretic (and non-homotopy-theoretic) models of dependent type theory also model HITs, using a generalisation of the initial-algebra semantics of ordinary inductive types.
%
Precisely, we show that \todo{\ldots} .
\end{abstract}


\tableofcontents

\section{Introduction}

The homotopy-theoretic interpretation of constructive type theory~\cite{...}, like any bridge between previously unrelated subjects, allows ideas and theorems to percolate in both directions.
On the one hand, because any well-behaved homotopy theory admits a model of type theory, we can use formal type-theoretic methods to prove homotopy-theoretic theorems.
On the other hand, examination of these models suggests new principles that can be added to type theory, making it more powerful and expressive, and also increasing the range of homotopy-theoretic theorems that can be proven formally.
So far, there are two important new type-theoretic principles that have been suggested by homotopy-theoretic models.
The first is Voevodsky's \emph{univalence axiom}; this has been discussed in detail elsewhere~\cite{klv:ssetmodel}, and we will have very little to say about it in this paper.
Our concern here is with the second, known as \emph{higher inductive types (HITs)}.

The basic idea of HITs was initially conceived at the Oberwolfach meeting in February 2011 by the present authors along with Bauer and Warren.
The first real application of HITs was the second author's formalized proof that $\pi_1(\circtype)=\lZ$, using a HIT definition of the circle $\circtype$~\cite{ls:pi1s1}.
Since then, many people have contributed to the further development of HITs; we will summarize some of their contributions in \cref{sec:hit-apps} below.
The syntax and use of HITs is explained by way of many examples (and some imprecise general remarks) in Chapter 6 of the Homotopy Type Theory book~\cite{hottbook}, while many of their recent applications can be found in its Chapter 8.

However, what is still missing from the literature is a precise specification of the rules for a sufficiently general class of HITs and a proof that these HITs really do exist in homotopy-theoretic models of type theory, analogous to the proofs in~\cite{klv:ssetmodel,shulman:invdia,shulman:elreedy} that the univalence axiom holds in (some) such models.
This is what we aim to provide in the present paper.
The central ideas of the construction were developed by the authors in the summer of 2011, and disseminated as talks and sketchy notes over the next few years, but have not been written out comprehensively until now.


\subsection{What are HITs?}
\label{sec:what-are-hits}

There are many different ways to motivate HITs.

From a homotopy-theoretic point of view, they provide a way to construct interesting homotopy types in type theory.
Homotopy type theory (with univalence, but without HITs) excels at proving formal theorems about \emph{general} homotopy types, such as the ``5-lemma'' for fibration sequences or an ``unstable octahedral axiom'' for composites of fibrations.
But it suffers from a paucity of ways to obtain \emph{particular} homotopy types, such as spheres, tori, manifolds, Eilenberg--MacLane spaces, etc.
Voevodsky's univalence axiom can be used for this to a certain extent --- for example, one can define the classifying space of a group $G$ as the type of $G$-torsors --- but this tends to require ``resizing axioms'' and is limited in its flexibility.

Higher inductive types remedy this situation, and can be thought of a type-theoretic analogue of the basic homotopical notion of \emph{cell complexes}.
They include both ``small, concrete'' cell complexes, such as CW presentations of spheres and tori, and ``large, abstract'' cell complexes such as those appearing in the construction of Postnikov towers and localizations by Quillen's small object argument.
Moreover, they provide a concise language for speaking about the latter that avoids referring explicitly to small objects and transfinite compositions.
(From this perspective, ordinary inductive types are \emph{0-dimensional} cell complexes.)

From a type-theoretic point of view, HITs provide a way to postulate equalities and construct quotients, obviating the need for ``setoids'' and all their corresponding hassles.
Bishop~\cite{bishop:fca} famously claimed that to specify a \emph{set}, one must specify how to construct its elements, and also specify when two such elements are equal.
Ordinary inductive types in type theory excel at specifying how to construct the elements of a set, but leave no flexibility in how to specify their equalities.
The standard solution is to equip each type with a secondary ``type of equalities'', forming a structure called a \emph{setoid}; this mostly works but results in a terrific amount of bookkeeping to carry around the setoid equalities everywhere.
Instead, higher inductive types augment ordinary inductive types with a basic way to ``specify the equalities between elements''.
The resulting equalities are actual equalities in the Leibniz sense, hence require no bookkeeping; they are automatically respected by everything in sight.
(In a homotopical world, the analogue of a setoid is an $\infty$-groupoid in type theory~\cite{coquand...}, but similar considerations apply.)

From a category-theoretic point of view, HITs provide a concise language for presentations of monads.
It is well-known that categorically, ordinary inductive types are free algebras for polynomial endofunctors.
Here an ``algebra for an endofunctor'' $F$ means nothing more than an object $X$ with a map $FX \to X$.
If $F$ is additionally a \emph{monad}, then we also have ``monad-algebras'', for which the map $FX \to X$ must satisfy associativity and unitality conditions.
In well-behaved categories, every polynomial endofunctor $F$ gives rise to a \emph{free monad} $\freemonad{F}$, so that that $F$-endofunctor-algebras are equivalent to $\freemonad{F}$-monad-algebras; thus we could equally well say that ordinary inductive types are free algebras for free monads.
However, the monads that arise naturally in mathematics are usually not free; but they are \emph{presented}, meaning that they are a colimit in the category of monads of a diagram consisting of free monads.
Higher inductive types, then, provide free algebras for these more general \emph{presented} monads.
(In homotopical models, these monads must be ``homotopically'' presented, which means roughly that the relevant colimit of monads must be a ``homotopy colimit''.
We will make this precise when we discuss higher W-types.
It is natural to conjecture that these are also colimits in the $(\infty,1)$-category of $(\infty,1)$-monads, but we have not investigated this question.)

Note that the type-theoretic and category-theoretic motivations presented above do not depend on homotopy theory at all.
Indeed, higher inductive types \emph{could} have been invented completely independently of the homotopical interpretation of type theory.
Although historically, it was the first, homotopy-theoretic, motivation which gave rise to them, they are still interesting and highly nontrivial even in Extensional Type Theory, where there is no higher homotopical information.
In particular, they supply well-behaved quotients and free algebras of all sorts, going beyond what exists in elementary toposes, and even beyond what can be constructed in ZF set theory without the axiom of choice, while nevertheless remaining constructive (at least in many, and conjecturally all, senses of the word).


\subsection{Some examples of HITs}
\label{sec:hit-egs}

Recall that an ordinary \emph{inductive type} is specified by some number of \emph{constructors}, which take as input some data (possibly recursively involving the inductive type being defined) and output an element of the inductive type.
For instance, the natural numbers are generated by a constructor \fzero that requires no input and a constructor \fsucc that takes a natural number as input; the unit type is generated by a single constructor \ftt that requires no input; and the empty type is generated by no constructors at all.

Roughly speaking, a \emph{higher} inductive type can have these same sorts of constructor, but also ``constructors'' whose output is not an \emph{element} of the type being defined, but an \emph{equality} between two such elements.
In homotopy type theory, equalities are identified with \emph{paths}, and so we call this new sort of constructor a \emph{path-constructor}.
The old sort of constructors may then be called \emph{point-constructors} for clarity.

It is of central importance that the paths constructed by path-constructors, like the points constructed by point-constructors, are \emph{new} paths, not coinciding with any path that ``already existed''.
For example, consider perhaps the simplest nontrivial HIT, the \textbf{circle} $\circtype$: this is generated by one point-constructor, called \fbase, and one path-constructor, called \floop, which constructs a path from \fbase to \fbase.
Of course, we already knew that \fbase was equal to \fbase, by reflexivity; but the path given by \floop is a \emph{new} such path that is not equal to reflexivity.%
\footnote{More precisely, it is not \textit{a priori} equal to reflexivity.
  Actually \emph{proving} that it is not equal to reflexivity is analogous to proving that the injections of a sum type are disjoint, and requires the univalence axiom; see~\cite{hottbook,ls:pi1s1}.}
From the homotopical point of view, we are describing the circle $\circtype$ as a cell complex with one 0-cell (\fbase) and one 1-cell (\floop).

The existence of \floop also entails the existence of many other paths from \fbase to \fbase; for instance, we can compose \floop with itself (i.e.\ apply the transitivity of equality), or invert it (i.e.\ apply the symmetry of equality), and so on.
Saying that \floop is an inductive generator of $\circtype$ means that \emph{none} of these paths are (\textit{a priori}) equal to each other.
The theorem that $\pi_1(\circtype)=\lZ$ amounts to showing that, in the presence of the univalence axiom, every path we get is (propositionally) equal to $\floop^n$ for exactly one integer $n$.

Of course, we can also add paths between points that were not previously equal at all.
For instance, the \textbf{interval} $I$ is generated by two point-constructors, \fzero and \fone, and one path-constructor \fseg which constructs a path from \fzero to \fone.
Unsurprisingly, this turns out to be equivalent to the unit type (but it is not completely boring either, e.g.\ its existence implies function extensionality).

We can also add more than one path between two points.
For instance, if $A$ is any type we can define the \textbf{suspension} of $A$, denoted $\susp A$, which has two point-constructors $\fnorth$ and $\fsouth$ and one path-constructor $\fmerid$ which constructs one path from $\fnorth$ to $\fsouth$ for every element of $A$.
The circle $\circtype$ is equivalent to the suspension of the 2-element type, while by iteratively suspending it we can define higher-dimensional spheres: $\spheretype {n+1}$ is $\susp {\spheretype n}$.

Additionally, since we are interested not only in \emph{whether} two points are equal, but \emph{how many} paths there are between them, we also allow path-constructors which construct \emph{paths between paths}, or \emph{paths between paths between paths}, and so on.
Homotopically, these correspond to cells of higher dimension in a cell complex, and indeed any (finite) cell complex can be presented as a HIT.
For instance, the \textbf{torus} $\torustype$ has one point-constructor \fbase, two path-constructors $\fmerid_1$ and $\fmerid_2$ giving paths from \fbase to itself, and one ``2-path-constructor'' giving a path relating the composites of $\fmerid_1$ and $\fmerid_2$ in both orders.
And the \textbf{2-sphere} $\spheretype 2$ has one point-constructor \fbase and one 2-path-constructor \fsurf giving a path from the \emph{reflexivity} path of \fbase to itself.

The ability to assert equalities also means that we can construct \textbf{colimits} of types.
With ordinary inductive types we can construct coproducts (sum types) and an initial object (the empty type), but not other colimits such as coequalizers or pushouts.
With HITs, however, these are easy to do.
For example, the coequalizer of two functions $f,g:A\to B$ has one point-constructor $q:B\to \fcoeq(f,g)$ and one path constructor giving for each $a:A$ a path from $q(f(a))$ to $q(g(a))$.

The real power of HITs starts to show itself when we introduce path-constructors with recursive inputs, analogous to recursive point-constructors like \fsucc for the natural numbers.
The first such example is the \textbf{squash}~\cite{nuprlbook} or \textbf{bracket type}~\cite{ab:bracket-types} of a type $A$, which is intended to be a type $\brck{A}$ that contains at most one element, and does so exactly if $A$ has an element.
We can define this as a HIT with one point-constructor that takes as input an element of $A$, and one path-constructor which gives for any two elements $x$ and $y$ \emph{of $\brck{A}$ itself}, a path from $x$ to $y$.
The point-constructor ensures that if $A$ is inhabited then so is $\brck{A}$, while the path-constructor ensures that $\brck{A}$ has no more than one element.%
\footnote{In homotopy type theory, the question is a little more subtle: in addition to ensuring that any two elements of $\brck{A}$ are related by a path, we would want to ensure that any two \emph{paths} are related by a 2-dimensional path, and so on.
  Fortunately, the single path-constructor of $\brck{A}$ is sufficient to ensure this automatically.}

The bracket type is also known as the \textbf{$(-1)$-truncation}: it universally truncates $A$ into a $(-1)$-type, a homotopy type that is contractible if inhabited.
We can also construct $n$-truncations for all higher $n$.
For instance, the \textbf{$0$-truncation} $\trunc 0 A$, also known as $\pi_0(A)$, has the same point-constructor as $\brck{A}$, along with a 2-path-constructor saying that for any two elements $x$ and $y$ of $\trunc 0 A$, and any two paths $p$ and $q$ from $x$ to $y$, there is a path from $p$ to $q$.
In homotopy theory, the $n$-truncations of a type are called its \emph{Postnikov tower}.

By including both recursive point-constructors and recursive path-constructors, we can directly construct \textbf{free algebras} of any desired sort.
For instance, the \textbf{free group} $\freegroup{A}$ on a type $A$ is generated by one point-constructor taking input from $A$; three point-constructors taking respectively no input (the identity element), two inputs from $\freegroup{A}$ itself (the multiplication), and one input from $\freegroup{A}$ (the inversion); and various path-constructors asserting the group axioms (plus the above 0-truncation constructor, since we want a free group rather than a free $\infty$-group).
The resulting induction principle of the HIT $\freegroup{A}$ says almost verbatim that it \emph{is} the free group on $A$.
In this way, HITs enable us to ``construct'' free structures of all sorts merely by asserting their universal property.

One final example will serve to suggest the extreme flexibility of HITs.
Let $f:A\to B$ be a given function and $X$ a type, and consider the HIT $\local{f}{X}$ with the following constructors:
\begin{enumerate}
\item a point-constructor taking input from $X$.
\item two point-constructor \fext and $\fext'$, both taking as input a function $g:A\to \local{f}{X}$ and an element $b:B$.
\item a path-constructor that for $g:A\to \local{f}{X}$ and $a:A$ we have $\id{\fext(g,f(a))}{g(a)}$.
\item a path-constructor that for $h:B\to \local{f}{X}$ and $b:B$ we have $\id{\fext'(h\circ f,b)}{h(b)}$.
\end{enumerate}
Then $\local{f}{X}$ is none other than the \textbf{localization} of $X$ at $f$: the universal type equipped with a map from $X$ which is \textbf{$f$-local} in the sense that $(\blank\circ f):(\local{f}{X})^B \to (\local{f}{X})^A$ is a homotopy equivalence.
(We have expressed ``being a homotopy equivalence'' as ``having a homotopy left inverse and also a homotopy right inverse'', because this correctly makes ``the type of homotopy equivalences'' into a subtype of the type of functions.
See e.g.~\cite[Chapter 4]{hottbook} for further discussion.)
Localizations are ubiquitous in homotopy theory, generally being constructed as transfinite cell complexes with the small object argument; HITs allow us to construct them just like free groups, merely by asserting their universal property.


\subsection{Applications of HITs}
\label{sec:hit-apps}

To show the usefulness and fruitfulness of HITs, we briefly survey some known applications.
Many of these results can be found in~\cite{hottbook}.

A fair amount of work so far has concentrated on reproducing homotopy-theoretic calculations in type theory, such computations of homotopy groups of spheres.
Here the $n^{\mathrm{th}}$ homotopy group $\pi_n(X)$ of a type $X$ (equipped with a basepoint) is defined to be the $0$-truncation of its $n$-fold loop space $\Omega^n X$ (the latter being definable without HITs).
The first such computation, as mentioned above, was the second author's proof that $\pi_1(\circtype)=\lZ$, and also $\pi_n(\circtype)=0$ for $n>1$, by showing that in fact $\Omega \circtype = \lZ$.
Licata~\cite{ls:pi1s1} later improved this proof, isolating a general method now known as ``encode--decode'' for computing with loop spaces of HITs.
Using this method, he and Brunerie calculated $\pi_k(\spheretype n) = 0$ for $k<n$ and $\pi_n(\spheretype n) = \lZ$~\cite{lb:pinsn}.
The first author and Brunerie used the Hopf fibration to show $\pi_3(\spheretype 2) = \lZ$, and Brunerie used the James construction to show $\pi_4(\spheretype 3) = \lZ/2$.

HITs have also proven useful in more abstract homotopy-theoretic theorems.
The first author proved the Freudenthal suspension theorem in type theory, and with Licata and Finster generalized it to the Blakers--Massey theorem; the role of HITs being to construct suspensions and pushouts (as well as define homotopy groups by truncation).
The second author proved the van Kampen theorem, and Hou developed the theory of covering spaces.
Licata and Finster~\cite{lf:emspaces} have constructed Eilenberg--MacLane spaces $K(G,n)$, enabling the represented definition of cohomology and verification of the Eilenberg--Steenrod axioms.
Finally, Voevodsky constructed the long exact sequence associated to a fibration, and the second author used this to construct the cohomological Serre spectral sequence.
There is every prospect that this formalization of homotopy theory in type theory will continue fruitfully.

As suggested above, HITs also have applications outside of homotopy theory.
Spitters and Rijke~\cite{rs:hottsets} have used HIT colimits to show that the subcategory of ``sets'' in homotopy type theory is a $\Pi W$-pretopos.
Note that these ``sets'' are just types whose Leibniz equality satisfies UIP, not ``setoids'' equipped with any additional equality structure.
Awodey has constructed a ``cumulative hierarchy'' of ``membership-based sets'' as a HIT, which satisfies a constructive version of the ZF axioms.
Bauer has defined a set of ``Cauchy real numbers'' as a HIT (more precisely, a higher inductive-inductive type) that, unlike a simple quotient of Cauchy sequences, is constructively Cauchy-complete.
And the second author has defined a constructive version of Conway's surreal numbers as a higher inductive-inductive type, generalizing Taylor's ``plump ordinals''.

Finally, HITs may even have direct applications to theoretical computer science.
Angiuli, Morehouse, Licata, and Harper~\cite{amlh:htpy-patch} have used them to model a theory of ``patches'' for version control systems.


\subsection{Layers of complexity}
\label{sec:layers-complexity}

The goal of this paper is to formulate precise syntax for a reasonably general class of HITs, and show that they exist in a reasonably general class of homotopical models.
However, our most general version requires dealing with many separate technical problems at once, so for expositional clarity we build up to it in stages.
The issues that must be dealt with include the following:
\begin{enumerate}
\item Path-constructors (the basic distinguishing feature of HITs).
  In particular, when specifying the elimination and computation rule of a HIT, we need to know how (dependent) functions ``act on paths''.\label{item:issue:ap}
\item Higher path-constructors, eventually including those of arbitrary dimension.
  This brings extra complexity in the specification of their boundaries, since they must lie in iterated higher identity types.
\item Parameters to the specification.  For example, the natural numbers are a single inductive type with no parameters, and likewise the circle is a HIT with no parameters; whereas a coproduct type $A+B$ is defined parametrically over $A$ and $B$, and likewise the suspension $\susp A$ is parametric in $A$.
\item Multiple constructors.
  The constructors of an ordinary inductive type are always completely independent, in that none of them can ``refer to'' the others in any way.
  In particular, any finite number of constructors can always be ``coalesced'' into a single one, as is done when representing arbitrary inductive types by W-types.
  For HITs this is no longer the case, because the boundary of one path-constructor generally needs involves previous constructors (for example, the source and target of the path-constructor \floop of $\circtype$ are the previous constructor \fbase).
  This means that the constructors of a HIT must be given \emph{in an order}, with each allowed to refer to the previous ones, and we need to specify the syntax and semantics of ``$n$-constructor HITs'' inductively on $n$.

  One could imagine relaxing the restriction that constructors can only refer to previous ones, allowing all sorts of mutual references, but it is not clear whether our methods could be extended to support that.
  Note, though, that since point-constructors have no way to refer to other constructors at all, they might as well all be specified first.
\item Recursive constructors, such as $\fsucc$ for the natural numbers and the truncation-constructor for $\brck{A}$.
  This mean specifying the allowable ways that a HIT can appear in the domains of its own constructors.
  The usual syntactic restriction is ``strict positivity'', which semantically ensures an ``accessibility'' property of a certain functor.
\item Delimiting the terms that may specify the source and target of a path-constructor (or more generally the ``boundary'' of a higher path-constructor).
  We recall below an example from~\cite[\S6.13]{hottbook} showing that these cannot be completely arbitrary.
  Semantically, they have to be ``natural transformations'', but it requires some work to specify a corresponding syntactic restriction.\label{item:issue:naturality}
\item Fibrancy.
  In homotopical models, types are generally interpreted by the fibrant objects, or more generally the fibrations, of a Quillen model category.
  However, the categorical constructions we use generally do not preserve fibrancy, so we need to incorporate a ``fibrant replacement'' in an algebraically well-behaved way.
\item Stability under pullback.
  In type theory all constructions must be strictly preserved by substitution, but in categorical models they are generally only preserved ``weakly'', up to isomorphism or even only up to homotopy.
  This is particularly problematic for fibrant replacement, which in general is not preserved by pullback \emph{at all}.
\item Path operations in boundaries.
  The three previous issues interact in a particularly troublesome way when we want the boundary of a path-constructor to involve operations such as path composition, such as for the 2-path-constructor of $\torustype$.
  Because such compositions generally only exist in fibrant objects, this seems to require that we incorporate fibrancy ``at all stages of the' construction'', but this makes the problem of stability much more difficult.
  Moreover, path compositions are only ``natural up to homotopy'', whereas our current machinery requires strict 1-categorical naturality for the source and target.
  We do not have a complete solution to this problem, but we will present a workaround that covers the majority of use cases.\label{item:issue:pathops}
\item Preservation of size.
  In a type theory with universes, one would like the universes to be closed under all type forming operations, including HITs with type parameters.
  Semantically, however, this corresponds to having a construction on fibrations that preserves the size of its \emph{fibers}, even if the base object is of a larger size, and this is generally not the case when a construction involves fibrant replacement.
  We do not have a satisfactory solution to this problem.\label{item:issue:size}
\end{enumerate}

There are also further levels of complexity that one may imagine incorporating, but which we leave to future work:

\begin{itemize}
\item Path-constructors whose dimension depends on a parameter, such as the $n$-dimensional spheres used in~\cite{lb:pinsn}.
\item Constructors that add paths of \emph{all} dimensions, such as the localizations of~\cite{shulman:univprop-nofunext}.
\item Higher inductive families.
  In addition to parameters, ordinary inductive types may have \emph{indices}, such as lists that are indexed by their length (usually called ``vectors'').
  The difference is that although we define the coproduct types $A+B$ for all $A$ and $B$ at once, each individual type $A+B$ has its own induction principle; whereas the type of 3-element lists has no induction principle on its own but only as part of the whole family of $n$-element lists for all $n$.
\item Mutually defined higher inductive types.
  As with ordinary inductive types, these could probably be encoded as higher inductive families over a finite type.
\item Higher inductive-inductive types.
  Ordinary inductive-inductive types allow defining a type and a type family over that type by mutual induction.
  Some ``higher inductive-inductive types'' are used in~\cite[Chapter 11]{hottbook}, but we will not attempt to discuss them in this paper.
  In fact, even the existence of ordinary inductive-inductive types in homotopical models is unproven.
\item Higher inductive-recursive types.
  If these exist, they can be used to construct univalent Tarski-style universes inside any given univalent universe~\cite{shulman:hiru-tdd}.
  But as in the inductive-inductive case, even the existence of ordinary inductive-recursive types in homotopical models is unproven.
\end{itemize}


\subsection{A hybrid type theory}
\label{sec:hybrid-tt}

To deal with all these technical problems, we have found it convenient to work in a slightly bizarre type theory, which is a three-way hybrid between classical Martin-L\"of type theory, the ``cubical type theories'' of~\cite{bch:tt-cubical,ak:cubical,lb:cubical-tt}, and the ``homotopy type system'' of~\cite{vv:hts}.
Our primary interest is in constructing HITs in models of ordinary MLTT.
However, by incorporating some features of these other two theories (which are valid in all the homotopical models we consider), we are able to deal more cleanly with some of the technical problems.
We can then translate the results back into ordinary MLTT.
We do not have a fully general algorithm for this translation,\msnote{Anything better we can say here?} but we will describe how it works for several examples.

Here are the distinguishing features of our hybrid type theory:
\begin{itemize}
\item There are no universe types.
  Instead, ``being a type'' is a separate judgment form.
  We make this choice for two reasons: firstly, in many homotopical models it is not known how to construct universes; and secondly, we do not know how to deal with issue~\ref{item:issue:size} above.
  (It should be noted, however, that all the \emph{homotopy-theoretic} results about HITs mentioned in \cref{sec:hit-apps} require the presence of a universe satisfying the univalence axiom.
  Such a universe does exist in some models, such as those of~\cite{klv:ssetmodel,shulman:invdia,shulman:elreedy}; while other models of interest, such as those arising from $(\infty,1)$-toposes, have instead a ``weakly Tarski'' universe, which is conjecturally sufficient for these proofs.)
\item In fact, as in~\cite{vv:hts}, we include two different judgment forms for types: one for ``fibrant'' types and one for non-fibrant (i.e.\ not-necessarily-fibrant) ones.
  The embedding of ordinary MLTT in our hybrid theory sees only the fibrant types; the non-fibrant ones enable us to give a clean treatment of issue~\ref{item:issue:naturality} above without running into the failure of pullback to preserve fibrant replacement.
\item We include the ``standard'' type constructors of $\Pi$, $\Sigma$, and the unit type \unittype.
\item Identity types are not defined as inductive families.
  Instead, as in~\cite{lb:cubical-tt}, there is an additional context of ``dimension variables'', with identity types defined by a sort of ``dependent abstraction'' over a dimension variable.
  Homotopically, this corresponds to identifying ``paths'' with ``maps out of an interval object''.
  This results in a much-better-behaved notion of ``applying a function to a path'', which makes it much easier to specify the elimination and computation rules for HITs (issue~\ref{item:issue:ap} above).
  The ``cubes'' resulting from multiple dimension contexts also figure into our workaround for issue~\ref{item:issue:pathops} above.
\item Unlike in~\cite{lb:cubical-tt} and other cubical type theories, however, we do not assert any ``Kan operations'' on the identity types, nor do we ``define'' the identity types by recursion over the structure of types.
  Instead, we assert that they satisfy the usual elimination and computation rules as if they were an inductive family.
  Of course, type-theoretically this is horrible because we are giving one type two different elimination rules, but it is valid in the models we consider, and it enables us to see ordinary MLTT as a fragment of our hybrid type theory.
\end{itemize}

\subsection{An outline of the paper}
\label{sec:outline}

The construction of category-theoretic models of type theory depends on (1) knowing that from the syntax of type theory one can construct the initial model of a certain essentially algebraic theory, and (2) knowing that ordinary categories give rise to models of that same theory.
The former fact is considered folklore in type theory, but in fact has not been carefully proven except for one particular type theory in~\cite{streicher:semtt}.
We will not attempt to prove it for our type theory either; instead, we will describe our type theories both ``syntactically'' in the traditional way and ``semantically'' in terms of the algebraic theories they are expected to correspond to.
Formally, therefore, what we will do is only part (2): we describe certain essentially algebraic theories and show that from certain Quillen model categories we can construct models of these theories.

We begin by laying out the base ``hybrid'' type theory, before any HITs are added.
In \cref{sec:syntactic-type-theory} we describe it syntactically in the traditional style, with judgments and variable binding.
Then in \cref{sec:semantic-type-theory} we describe its intended algebraic models, an enhancement of ``categories with families'' (CwF)~\cite{?}.\msnote{Are we actually using CwF, or something else?}
We also recall the coherence theorem of~\cite{lw:localuniv}, which shows that ``weakly stable'' or ``pseudo stable'' structure on such a CwF gives rise to strictly stable structure on a related CwF, and explain at the level of CwF how to see ordinary MLTT (without universes) as a reduct of our hybrid type theory (at the traditional syntactic level of \cref{sec:syntactic-type-theory}, this is clear because the rules of MLTT are included in ours).
Next, in \cref{sec:model-categories} we describe how we pass from homotopy theory (specifically, well-behaved Quillen model categories) to hybrid CwFs with weakly stable structure (to which the coherence theorem can therefore be applied), and show that when we forget down to ordinary MLTT we obtain the same models that have been considered elsewhere in the literature.

At this point we are finally ready to introduce HITs, by a series of examples that involve successively more of the issues discussed in \cref{sec:layers-complexity}.
In each case, we first set out the syntactic rules, then the operations on hybrid CwFs they are expected to correspond to, in both strictly and weakly stable forms, and extend the coherence theorem of~\cite{lw:localuniv} to show that weakly stable structure gives rise to strictly stable structure.
Then we show that the hybrid CwFs arising from model categories as in \cref{sec:model-categories} admit the weakly stable version of the structure; this is where the real heart of the paper lies.
Finally, we sketch how this structure can be transferred back to rules that make sense in ordinary MLTT.
\begin{itemize}
\item We begin in \cref{sec:syntax} with an overview of the syntax for HITs, so that the sections to follow can concentrate on the specifics relevant to particular examples.
\item \todo{An ordinary inductive type or two?}
\item In \cref{sec:circtype} we start with the simplest example of $\circtype$, which involves only path-constructors, multiple constructors, fibrancy, and a certain amount of stability.
  These are all issues which even the simplest of HITs must deal with.
\item In \cref{sec:susp} we consider the suspension $\susp A$, which introduces a type parameter $A$.
\item In \cref{sec:torustype} we consider the torus $\torustype$, which involves a higher path-constructor and also the cubical workaround for path operations in boundaries.
\item In \cref{sec:brck} we consider the propositional truncation $\brck{A}$, which in addition to a parameter $A$ involves a recursive path-constructor.
\item In \cref{sec:loopy} we take a brief hiatus to consider some non-examples: HITs that seem reasonable but are not covered by our setup.
  This motivates our solution to the problem of boundary specifications: they can be arbitrary terms belonging to a \emph{non-fibrant} version of the HIT specified by the previous constructors (thus preventing the appearance of path operations and ensuring strict naturality).
\item In \cref{sec:twoconstr-hwt} we consider our first general class of HITs: ``higher W-types'' with one point-constructor and one 1-path-constructor.
  Both constructors are parametrized by an arbitrary type family, like the single constructor of an ordinary W-type.
  These combine type parameters with recursive constructors, and additionally showcase our general solution to the problem of naturality.
\item Finally, in \cref{sec:hwt} we consider ``general higher W-types'', which can have arbitrarily many constructors (each parametrized by an arbitrary type family) of arbitrary dimension.
  At this point we have to induct over the number of constructors, and also specify precisely the syntax for the boundary of an $n$-dimensional cube.
\end{itemize}


\section{Syntactic type theory}
\label{sec:syntactic-type-theory}

In this section we describe our base hybrid type theory.

\subsection{Contexts and judgments}
\label{sec:cxt-jdg}

The absence of universes means that we need a separate judgment ``$A \type$'' indicating that $A$ is a type.
A type family (or dependent type) indexed by $A$ is then described by a hypothetical judgment $\jd{x:A |- B(x) \type}$.

We also include a judgment ``$A \fib$'' for ``fibrancy'' of the type (family) $A$.
Every fibrant type is also a type:
\[ \inferrule{\Gamma \vdash A\fib}{\Gamma \vdash A\type} \]

\subsection{Dependent products}
\label{sec:pi-syntax}

Any type family $\jd{x:A |- B(x) \type}$ has a dependent product $\prd{x:A} B(x)$ satisfying the usual rules, including the $\eta$-rule $f \jdeq \lam{x}f(x)$.
As usual, if $B(x)$ is independent of $x$, we write $A\to B$ for $\prd{x:A} B(x)$.
Notationally, the scope of $\prd{x:A}$ extends as far to the right as possible, so that $\prd{x:A} B(x) \to \sm{x:A} B(x)$ means $\prd{x:A} \big(B(x) \to \sm{x:A} B(x)\big)$.

If both inputs to a dependent product are fibrant, then so is the result:
\[ \inferrule{\Gamma \vdash A \fib \\ \Gamma, x:A \vdash B \fib}{\Gamma \vdash \tprd{x:A} B \fib} \]


\subsection{Dependent sums}
\label{sec:sigma-syntax}

Any type family $\jd{x:A |- B(x) \type}$ also has a dependent sum $\sm{x:A} B(x)$ satisfying the usual rules, including the $\eta$-rule.
As usual, if $B(x)$ is independent of $x$, we write $A\times B$ for $\sm{x:A} B(x)$.

If both inputs to a dependent sum are fibrant, then so is the result:
\[ \inferrule{\Gamma \vdash A \fib \\ \Gamma, x:A \vdash B \fib}{\Gamma \vdash \tsm{x:A} B \fib} \]



\subsection{Cubical identity types}
\label{sec:cubic-ident-types}

In ordinary MLTT, one defines the \emph{identity type} as an inductive family $\jd{x:A,y:A |- \id[A]{x}{y} \type}$ generated by reflexivity $\jd{x:A |- \refl_x : \id[A]xx}$.
Although its only introduction rule is reflexivity, the distinguishing feature of \emph{homotopy} type theory is that identity types can contain paths \emph{other} than $\refl$, corresponding to loops in $A$ viewed as a ``space''.
For this reason we will sometimes refer to elements of an identity type as \emph{paths}.

However, this definition of identity types is not ideal when discussing HITs, because certain equalities, notably those involving the application of functions to paths, are propositional rather than judgmental.
This makes complicated homotopy-theoretic proofs increasingly difficult, such as $T^2 = S^1\times S^1$~\cite{lb:torus}.
More seriously, it is a substantial obstacle to the semantic methods we plan to employ in this paper, which rely on \emph{strict} algebraic structures in model categories.

For this reason, we will \emph{not} define the identity types as inductive families.
Instead, we follow the route taken by the ``cubical type theory'' of~\cite{lb:cubical-tt}, introducing a basic notion of ``line in a type'' that can be internalized to yield identity types.
Such lines are encoded by a special context of ``dimension variables'' to the left of the ordinary context; thus a particular judgment might look like this:
\[ x\dim, y\dim \cb a:A \pr b:B \]
where $A$ might depend on $x$ and $y$, while $b$ and $B$ might depend on $x$, $y$, and $a$.
The semicolon separates the ``dimension context'' from the ordinary one.
It is helpful (and, as we will see, semantically valid) to think of ``$x\dim$'' as ``$x:I$'' where $I$ is a sort of ``interval type'';
placing such variables in a separate context just simplifies the theory and its semantics.
The theory is ``cubical'' because from this viewpoint a dimension context $x\dim, y\dim, z\dim$ corresponds to a ``cube'' $I\times I\times I$.

The dimension context admits the usual structural rules of exchange, contraction, and weakening, which is just to say that dimension variables behave like ordinary variables; and in addition there are two special values $0$ and $1$ (the ``endpoints of the interval'') that can be substituted for any dimension variable.
We write substitution of dimension variables with angle brackets to distinguish it from ordinary substitution; thus if $x\dim \vdash a:A$ then we have $y\dim \vdash a\dsubst{y}{x} : A\dsubst{y}{x}$ and $\vdash a\dsubst{0}{x} : A\dsubst{0}{x}$.

In this setup, the identity type is defined roughly by ``abstracting over a dimension variable'';
semantically, this corresponds to the intuition that a path space consists of maps out of an interval.
Relative to an ordinary function abstraction, the main wrinkle is that we indicate in the identity type $\id{a}{b}$ the values $a$ and $b$ of the line at $0$ and $1$; semantically this corresponds to asking that $(0,1):1+1 \to I$ be a ``cofibration''.

Specifically, the rule for forming identity types looks just like the one in MLTT, except for the presence of an extra dimension context $\Psi$:
\begin{equation}
\inferrule{\Psi;\Gamma \vdash A \type \\ \Psi;\Gamma \vdash a_0 :A \\ \Psi;\Gamma \vdash a_1:A}{\Psi;\Gamma\vdash \id[A]{a_0}{a_1}\type}\label{eq:cubical-idform-nondep}
\end{equation}
(Actually, there is a further enhancement to this which we postpone discussing until later.)
But the rule for introducing terms in an identity type looks like $\lambda$-abstraction:
\[ \inferrule{\Psi,s\dim\cb\Gamma\pr u:A \\ \Psi;\Gamma \vdash u\dsubst0s \jdeq a_0 \\ \Psi;\Gamma \vdash u\dsubst1s \jdeq a_1}{\Psi;\Gamma \vdash \dlam s u : \id[A]{a_0}{a_1}} \]
(we use the modified notation $\dlamsym$ to indicate that it is a different kind of abstraction)
and the rule for elimination looks like application:
\[ \inferrule{\Psi;\Gamma \vdash u:\id[A]{a_0}{a_1} \\ \Psi \vdash r \dim}{\Psi;\Gamma \vdash u\dapp r : A\dsubst{r}{s}} \]
We also have corresponding computation rules:
\[ \inferrule{\Psi,s\dim\cb\Gamma\pr u:A \\ \Psi \vdash r \dim}{\Psi;\Gamma \vdash (\dlam s u)\dapp r \jdeq u\dsubst{r}{s}} \]
\[ \inferrule{\Psi;\Gamma \vdash u:\id[A]{a_0}{a_1}}{\Psi;\Gamma \vdash u\dapp 0 \jdeq a_0}
\hspace{1cm}\inferrule{\Psi;\Gamma \vdash u:\id[A]{a_0}{a_1}}{\Psi;\Gamma \vdash u\dapp 1 \jdeq a_1} \]

As an example of how to use these identity types, we can define the operation \ap (for ``Action on Paths'' or ``APplication to an equality'') associated to a function, which takes a path between points in the domain to a path between their images in the codomain.
Given a function $f:A\to B$ and points $a_0,a_1:A$, we can form\footnote{This entire discussion should really take place in an arbitrary context $\Psi;\Gamma$, but for clarity we omit this from the notation.}
\[ r\dim \cb p:\id[A]{a_0}{a_1} \pr p\dapp r : A. \]
Now, because the ordinary rules of type theory, including ordinary function application, are valid \emph{in any context}, including a nontrivial dimension context, we can form
\[ r\dim \cb p:\id[A]{a_0}{a_1} \pr f(p\dapp r) : B. \]
Now we can abstract over $r$ to obtain
\[ \emptycxt \cb p:\id[A]{a_0}{a_1} \pr \dlam{r} f(p\dapp r) : \id[B]{f(a_0)}{f(a_1)} \]
(where $\emptycxt$ denotes an empty dimension context).
This is valid, according to the introduction rule, because 
\[ (f(p\dapp r))\dsubst0r \jdeq f((p\dapp r)\dsubst0r) \jdeq f(p\dapp 0) \jdeq a_0 \]
and similarly for $1$.
We can thus define $\ap_f(p)$ to be $\dlam{r} f(p\dapp r)$, and $\ap_f$ itself to be $\lam{p}\dlam{r} f(p\dapp r)$.

As is well-known, we can also define $\ap_f$ using the eliminator for $\fId$ defined as an inductive family.
However, the one we obtain from dimension abstraction is better-behaved.
For instance, given also $g:B\to C$, we can compute
\begin{multline*}
\ap_g (\ap_f(p))
\jdeq \ap_g(\dlam{r} f(p\dapp r))
\jdeq \dlam{s} g((\dlam{r} f(p\dapp r))\dapp s)\\
\jdeq \dlam{s} g(f(p\dapp s))
\jdeq \dlam{s} (g \circ f)(p\dapp s)
\jdeq \ap_{g\circ f}(p).
\end{multline*}
This is a \emph{judgmental} equality, whereas for $\ap_f$ defined with the inductive eliminator it would be only propositional (i.e.\ a term in a higher identity type).
Similarly, if we define $\refl_a$ to be the ``constant path'' $\dlam{r} a$, then we have
\[ \ap_f(\refl_a)
\jdeq \dlam{r} f((\dlam{r}a)\dapp r)
\jdeq \dlam{r} f(a)
\jdeq \refl_{f(a)}.\]
This equality does hold judgmentally for the traditional $\ap_f$, so it is good to know that this is still the case for the cubical one.

The real power of cubical identity types, however, comes from their ability to seamlessly represent \emph{dependent} or \emph{heterogeneous} identity types (``dependent paths'' or ``paths over paths''), which are essential when working with HITs.
The idea of dependent paths is that given a type $A$ and a type family $B$ over $A$, for points $x,y:A$ and a path $e:\id[A]xy$ and points $u:B(x)$ and $v:B(y)$, we need to know what it means to say that ``$u$ and $v$ are related by a path (or an equality) over $e$''.
The ordinary identity type cannot be applied to $u$ and $v$, since their types $B(x)$ and $B(y)$ are different; instead we need a new ``type of paths from $u$ to $v$ lying over $e$'' which we will write as $\idover[B]{u}{v}{e}$.
There are various ways to define this type in ordinary type theory, such as:
\begin{enumerate}
\item If we first define the \emph{transport} operation $\transf{e}:B(x) \to B(y)$ (using the eliminator for identity types), then we can define $\idover[B]{u}{v}{e}$ to be $\id[B(y)]{\transf{e}(u)}{v}$.
  This is the definition used by~\cite{hottbook} and~\cite{hottcoq}.\label{item:idover1}
\item We could instead use $\id[B(x)]{u}{\transf{(\opp{e})}(v)}$, where $\opp{e}:\id[A]{y}{x}$ is the inverse path of $e$ (i.e.\ $\opp{(\blank)}$ witnesses the symmetry of equality).\label{item:idover2}
\item We could define $\idover[B]{u}{v}{e}$ by using the eliminator for identity types on $e$, with $\idover[B]{u}{v}{\refl_x}$ defined to be $\id[B(x)]{u}{v}$.
  This is the definition used by~\cite{hottagda}.\label{item:idover3}
\item \msnote{Is this what Dan and Guillaume used in the cubical proof of the torus?}
 We could define $\idover[B]{u}{v}{e}$ as an (ordinary) inductive family, with a single constructor saying that for any $x:A$ and $u:B(x)$ we have $\refl_u : \idover[B]{u}{u}{\refl_x}$.\label{item:idover4}
\end{enumerate}

In cubical type theory, we instead obtain dependent paths by using a simple extension of the formation rule for identity types, in which the type $A$ can depend on the dimension variable:
\[ \inferrule{\Psi,s\dim \cb \Gamma \pr A \type \\ \Psi;\Gamma \vdash a_0 :A\dsubst0s \\ \Psi;\Gamma \vdash a_1:A\dsubst1s}{\Psi;\Gamma\vdash \id[s.A]{a_0}{a_1}\type}\]
Compared to~\eqref{eq:cubical-idform-nondep}, the main difference is the presence of $s\dim$ in the hypothesis $\Psi,s\dim \cb \Gamma \pr A \type$.
If we view identity types as ``function types'' out of the interval, then this corresponds to allowing dependent functions, like the generalization from $A\to B$ to $\prd{x:A} B(x)$.
To record this dependency of $A$ on $s$, we modify the notation for the identity type to write $\id[s.A]{a_0}{a_1}$ rather than $\id[A]{a_0}{a_1}$, indicating that the dimension variable $s$ may occur free in $A$ but is bound in $\id[s.A]{a_0}{a_1}$.

Now given the setup for dependent paths, i.e. $e:\id[A]xy$ and $u:B(x)$ and $v:B(y)$, we can form
\[ s\dim \vdash B(e\dapp s) \type \]
and therefore
\[ \vdash \id[s.B(e\dapp s)]{u}{v} \]
This is well-typed because
\begin{align*}
B(e\dapp s)\dsubst{0}{s} &\jdeq B(e\dapp 0) \jdeq B(x) \qquad\text{and}\\
B(e\dapp s)\dsubst{1}{s} &\jdeq B(e\dapp 1) \jdeq B(y).
\end{align*}
We thus take $\id[s.B(e\dapp s)]{u}{v}$ as the definition of the dependent path type $\idover[B]{u}{v}{e}$.
This allows us to use the \emph{same} definition of $\ap_f$ in the case when $f$ is a \emph{dependent} function $f:\prd{x:A} B(x)$: we deduce successively
\begin{align*}
  r\dim \cb p:\id[A]{a_0}{a_1} &\pr p\dapp r : A\\
  r\dim \cb p:\id[A]{a_0}{a_1} &\pr f(p\dapp r) : B(p\dapp r)\\
  \emptycxt \cb p:\id[A]{a_0}{a_1} &\pr \dlam{r} f(p\dapp r) : \id[r.B(p\dapp r)]{f(a_0)}{f(a_1)}.
\end{align*}
But by definition, $\id[r.B(p\dapp r)]{f(a_0)}{f(a_1)}$ is $\idover[B]{f(a_0)}{f(a_1)}{p}$.

As an example of the usefulness of this, note that if $B$ is a constant family, $B(x) \jdeq B$ for all $x$, then our definition of $\idover[B]{u}{v}{e}$ reduces judgmentally to $\id[B]{u}{v}$, and moreover the dependent $\ap_f$ specializes to the non-dependent one.
\emph{None} of the definitions~\ref{item:idover1}--\ref{item:idover4} in plain MLTT have this property, and this tends to cause significant headaches when doing path computations; cubical identity types thus solve this problem as well.

So far, however, we have not explained how the identity types are to inherit all the usual structure: composites of paths and higher paths forming an $\infty$-groupoid structure, transport in type families along paths, etc.
In MLTT, all of these data are derived from the eliminator for $\fId$ defined as an inductive family.
In cubical type theory, all of these data are essentially \emph{postulated} in a uniform way (as cubical ``Kan composition'' or ``Kan filling'' operations), and from them we can derive the usual eliminator of $\fId$ (though with only a propositional computation rule).
We do not want to take the latter route, because the form of the cubical Kan operations appears very specialized to the cubical set model of type theory, whereas we want our type theory to admit semantics in all the standard simplicial models as well (so that we can prove that HITs exist there).
Thus, we instead postulate the inductive eliminator for $\fId$ and its usual computation rule:
\[
\inferrule{\Psi;\Gamma,x,y:A,p:\id[A]xy \vdash C \type \\ \Psi;\Gamma,x:A \vdash c_\refl : C\subst{x,x,\refl_x}{x,y,p}}{\Psi;\Gamma,x,y:A,p:\id[A]xy \vdash J(\dots) : C \\ \Psi;\Gamma,x:A \vdash J(\dots) \jdeq c_\refl} \]
The resulting type theory is not, of course, computationally well-behaved, but that is not our concern here.

It is worth emphasizing that in our \emph{construction} of HITs we do not use this eliminator at all.
Instead the eliminator serves an auxiliary purpose.
For one thing, our verification in \cref{sec:model-categories} that the identity types in our models support this rule can be regarded as a consistency check that our ``identity types'' really deserve that name.
More importantly, the presence of the eliminator allows us to compare our well-behaved $\ap_f$ with the traditional ill-behaved one, which we denote $\ap'_f$.
Since both $\ap_f(\refl_a)$ and $\ap'_f(\refl_a)$ are equal to $\refl_{f(a)}$, we can use the eliminator again to show that they are propositionally equal; that is, we have a term
\[ \jd{a_0:A , a_1:A, p:\id[A]{a_0}{a_1} |- \fapeq(p) : \id[{\id[B]{f(a_0)}{f(a_1)}}]{\ap'_f(p)}{\ap_f(p)}} \]
This, in turn, enables us to translate the rules for our HITs, which involve $\ap_f$, into rules involving $\ap'_f$ instead.
(We will discuss this further in later sections.)
These translated rules are more complicated, but they can be stated in plain MLTT.
In this way, the use of cubical type theory can be entirely eliminated from our results, yielding a statement about HITs that exist in a certain class of models of MLTT.

Returning to the (non-)uses of the eliminator, it is true that some HITs appear to incorporate the $\infty$-groupoid operations in their definition, such as the composites of paths appearing in the boundary of the 2-path constructor of $\torustype$.
However, as mentioned in \cref{sec:layers-complexity}, we do not know how to model these directly; instead we use a cubical workaround that does not actually require the eliminator.


\subsection{Cofibrations}
\label{sec:cofibrations}

\todo{Experimental!}

We extend the syntax with one further judgment, denoted $\cof{i}{A}{B}$ and read as ``$c$ is a cofibration from $A$ to $B$''.
All cofibrations are also functions:
\[ \inferrule{\Gamma \vdash \cof{i}{A}{B}}{\Gamma \vdash i : A \to B} \]
(Perhaps this should be only an admissible rule?)
In particular, when $\Gamma \vdash \cof{i}{A}{B}$ it must be that $\Gamma \vdash A \type$ and $\Gamma \vdash B \type$.

We will have one axiomatic cofibration, whose codomain is an axiomatic type.
\[ \inferrule{\ }{\Gamma \vdash \Delta^1 \type} \qquad 
\inferrule{\ }{\Gamma \vdash 0 : \Delta^1} \qquad
\inferrule{\ }{\Gamma \vdash 1 : \Delta^1} \]
\[ \inferrule{\ }{\Gamma \vdash \cof{[0,1]}{2}{\Delta^2}} \]
Here $2$ denotes the non-fibrant coproduct $\unittype+\unittype$, and $[0,1]$ denotes the copairing.
Note that $\Delta^1$ is also not (assumed to be) fibrant.
Nothing prevents us from assuming further axiomatic cofibrations, as long as they exist in our desired models, but this will be the only one we need.
(Note, though, that semantically, it appears to be important that all cofibrations be defined in the empty context and pulled back to anywhere else from there.)

There is one ``introduction'' rule for constructing cofibrations:
\[ \inferrule{\Gamma \vdash \cof{i_1}{A_1}{B_1} \\ \Gamma \vdash \cof{i_2}{A_2}{B_2}}{\Gamma \vdash \cof{i_1\pop i_2}{(A_1 \times B_2) +_{A_1\times A_2} (B_1 \times A_2)}{B_1\times B_2}} \]
Here the pushout is again a non-fibrant one, and $i_1 \pop i_2$ denotes the ``pushout product'' map induced by the universal property of this pushout.
\msnote{Need to give rules for the non-fibrant pushout.}

The ``elimination'' rule for cofibrations is that exponentiating by a cofibration produces a fibration.
\todo{Make this its own type former of ``extensions''.}
\[ \inferrule{\Gamma \vdash \cof{i}{A}{B} \\ \Gamma, y:B \vdash C \fib \\ \Gamma, x:A \vdash c : C\subst{i(x)}{y}}{\Gamma \vdash \Big(\tsm{f : \tprd{y:B} C} \tprd{x:A} \eq{f(i(x))}{c}\Big) \fib} \]
Here $\fEq$ denotes the strict non-fibrant equality type.

There is a vague sort of ``harmony'' between the ``introduction'' and ``elimination'' rules in that the instances of elimination for $i_1$ and $i_2$ should imply the corresponding instance for $i_1 \pop i_2$.
In other words, given that the elimination rule is all we know about cofibrations, we might as well have the introduction rule (at least as long as non-fibrant pushouts exist).

If we replace dimension variables by variables of type $\Delta^1$, then with the axiomatic cofibration $\cof{[0,1]}{2}{\Delta^1}$ this rule enables us to define the cubical identity types.
Recall that the formation rule for the latter is:
\[ \inferrule{\Psi,s\dim \cb \Gamma \pr A \fib \\ \Psi;\Gamma \vdash a_0 :A\dsubst0s \\ \Psi;\Gamma \vdash a_1:A\dsubst1s}{\Psi;\Gamma\vdash \id[s.A]{a_0}{a_1}\fib}\]
On the other hand, if we substitute $\cof{[0,1]}{2}{\Delta^1}$ in the eliminator for cofibrations, we get
\[ \inferrule{\Gamma, y:\Delta^1 \vdash A \fib \\ \Gamma, x:2 \vdash a : A\subst{[0,1](x)}{y}}{\Gamma \vdash \Big(\tsm{f : \tprd{y:\Delta^1} A} \tprd{x:2} \eq{f(i(x))}{a}\Big) \fib} \]
To go from one to the other, we are just using the universal property of $2$ to copair up $a_0$ and $a_1$.
Similarly, the introduction rule for $\fId$ now corresponds to an actual abstraction over $\Delta^1$, paired with the reification of two judgmental equalities as an $\fEq$ between functions of domain $2$.
The elimination rule corresponds to projecting out the function of domain $\Delta^1$ and applying it, while the ``boundary'' computation rules result from projecting out the $\fEq$ term and applying the reflection rule for strict equality.

At this point, there may seem little benefit to reformulating the identity types in terms of cofibrations.
The payoff will come in \cref{sec:hwt} when we introduce path-constructors of arbitrary dimension.
In this case, the presence of the operation $\pop$ on cofibrations will allow us to formulate ``a constructor of arbitrary dimension'' as a \emph{single} rule, one of whose premises is a cofibration.
(It also makes the theory more general, in that we could also define ``HITs'' using any other cofibrations instead.)


\section{Semantic type theory}
\label{sec:semantic-type-theory}

\subsection{Hybrid comprehension categories}
\label{sec:hybrid-ccs}

\begin{defn}
  A \textbf{hybrid comprehension category (HCC)} consists of the following.
  \begin{itemize}
  \item A category \E, whose objects are called \emph{contexts}.
  \item Two (cloven) Grothendieck fibrations $\pi:\P\to\E$ and $\tau:\T\to\E$.
    The objects of $\P$ are called \emph{pretypes} and those of \T are called \emph{types}.
  \item A commutative diagram
    \begin{equation*}
      \vcenter{\xymatrix{
          \T \ar[dr]_\pi \ar[r]^\xi &
          \P \ar[d]^\tau \ar[r]^\chi &
          \E^\to \ar[dl]^{\mathrm{cod}} \\
          & \E
        }}
    \end{equation*}
    in which $\xi$ is injective on objects\msnote{Would we ever want to allow $\xi$ not to be injective on objects?}, fully faithful, and preserves cartesian arrows; and $\chi$ is fully faithful and takes cartesian arrows to pullback squares.
    Both $\chi$ and the composite $\chi\xi$ are called \emph{comprehension}.
  \item A discrete fibration $\delta : \C \to (\P \times_{\E} \P)_{\mathrm{cart}}$, where the codomain is the subcategory of $\P \times_{\E} \P$ containing all objects but only the morphisms that are cartesian over $\E$.  The objects of \C are called \emph{cofibrations}, and $\delta$ assigns to each cofibration its \emph{source} and \emph{target}.
  \item A commutative diagram
    \[ \xymatrix@C=.5pc{ \C \ar[rr]^-\zeta \ar[dr] && (\P^\to_\E)_{\mathrm{cart}} \ar[dl]\\
      & (\P \times_{\E} \P)\mathrlap{_{\mathrm{cart}}} } \]
    where $\P^\to_\E$ is the fiberwise arrow category of $\P$ and $(\P^\to_\E)_{\mathrm{cart}}$ is its subcategory containing only the cartesian morphisms.
    Here both diagonal maps are discrete fibrations, so $\zeta$ is automatically fully faithful and preserves cartesian morphisms; we additionally ask that $\zeta$ be injective on objects.\msnote{Again, might it not be injective?}
    We call $\zeta$ \emph{cofibrational comprehension}.
  \end{itemize}
  A HCC is \textbf{split} if $\pi$ and $\tau$ are split fibrations and $\xi$ preserves their cleavages.
\end{defn}

Split HCCs are the semantic version of our hybrid type theory.
As usual in the world of comprehension categories (and categories with attributes), the \emph{terms} belonging to a type or pretype are simply the sections of its comprehension.

For $\Gamma\in\E$, we write $\T(\Gamma)$ and $\P(\Gamma)$ for the fibers of $\tau$ and $\pi$ over $\Gamma$, and call their objects \emph{(pre)types in context $\Gamma$}.
We generally fail to notate the inclusion $\xi$, regarding types silently as pretypes whenever necessary.
If $A\in \P(\Gamma)$, we write $\Gamma.A$ for the domain of $\chi(A): \Gamma.A \to \Gamma$.
Finally, for a morphism $\sigma : \Delta \to \Gamma$ in \E and $A\in\P(\Gamma)$ or $\T(\Gamma)$, we write $\sigma_A : A[\sigma] \to A$ for a cartesian morphism lying over $\sigma$, and therefore $\sigma.\sigma_A : \Delta.A[\sigma] \to \Gamma.A$ for its comprehension.
Thus we have a pullback diagram:
\begin{equation}
  \vcenter{\xymatrix{
      \Delta.A[\sigma]\ar[r]^-{\sigma.\sigma_A} \ar[d]_{\chi(A[\sigma])} &
      \Gamma.A\ar[d]^{\chi(A)}\\
      \Delta \ar[r]_\sigma &
      \Gamma.
      }}
\end{equation}
In particular, while \E need not have all pullbacks, it does necessarily have all pullbacks along maps of the form $\chi(A) : \Gamma.A \to \Gamma$.

Note that a HCC has two underlying ordinary comprehension categories, namely $\pi$ and $\tau$.
It additionally has a notion of what it means for a morphism between pretypes in the same context to ``be a cofibration'', which is preserved by pullback.
In particular, composing a cofibration with an isomorphism yields another cofibration.


\subsection{The base type formers}
\label{sec:base-type-formers}

Recall that our base syntactic type theory has $\Pi$-types, $\Sigma$-types, and a unit type.
We now describe what these look like semantically.
As in~\cite{lw:localuniv}, we distinguish three types of stability for (pre)type constructors:
\begin{itemize}
\item A (pre)type constructor is \emph{strictly stable} if we can make a coherent choice of such constructors, all of whose data are strictly preserved by the chosen pullbacks.
  This is the sort of structure that is expected to correspond to the type constructors of syntactic type theory.
\item It is \emph{pseudo-stable} if we can make choices of such constructors that are preserved by pullback up to coherent isomorphism.
  This is the sort of structure that arises naturally in categorical models when fibrant replacement is not required.
\item It is \emph{weakly stable} if any pullback of it also has the appropriate property of a constructor of the same sort.
  This is the sort of structure that arises naturally in categorical models when fibrant replacement \emph{is} required.
\end{itemize}
The ``local universe'' coherence method of~\cite{lw:localuniv} gives a way to construct strictly stable structure from weakly stable structure, and we will need the full strength of this for higher inductive types.
However, in \emph{this} section, all the structure we consider will be at least pseudo-stable, for several reasons:
\begin{itemize}
\item Nothing in this section will require fibrant replacement, so in categorical models it is generally automatically pseudo-stable.
\item Moreover, if we assume uniqueness principles, corresponding to syntactic $\eta$-rules, weakly stable structure generally becomes automatically pseudo-stable.
\item Finally, pseudo-stability of some of the base structure will be important when constructing weakly stable HITs, for reasons similary to those remarked in~\cite[3.4.4.9--10]{lw:localuniv}.
\end{itemize}
We begin with dependent products.

\begin{defn}
  Let \E be a HCC.
  \begin{itemize}
  \item Let $A$ be a pretype in context $\Gamma$ and $B$ a pretype in context $\Gamma.A$.
    A \textbf{dependent product} of $B$ along $A$ is a pretype $\prod[A,B]$ in context $\Gamma$ and a map $\fapp_{A,B} : \prod[A,B][\chi(A)] \to B$ in context $\Gamma.A$ such that for each section $t:\Gamma.A \to \Gamma.A.B$ there is a chosen section $\lambda(t):\Gamma \to \Gamma.\prod[A,B]$ such that
    \[(\Gamma.A.\fapp_{A,B})\circ (1_{\Gamma.A},\lambda(t) \circ \chi(A)) = t.\]
  \item A dependent product is \textbf{strong}\msnote{Is there a better name for ``strong''?} if for any $t$ there is a \emph{unique} $\lambda(t)$.
  \item A dependent product is \textbf{weakly stable} if for any $\sigma:\Delta\to\Gamma$, the pair $\prod[A,B][\sigma]$ and $\fapp_{A,B}[\sigma.\sigma_A]$ can be extended to a dependent product of $B[\sigma.\sigma_A]$ along $A[\sigma]$.
  \item \E \textbf{has weakly stable dependent products} if any $A$ and $B$ have a weakly stable dependent product, which can be chosen to be a type if $A$ and $B$ are types.
  \item \E has \textbf{strictly stable dependent products} if we have an operation assigning to each $A$ and $B$ a dependent product, which is a type if $A$ and $B$ are, and such that all the data commutes strictly with pullback.
    This includes the operation $\lambda$, although of course that is preserved automatically if the dependent products are strong.
  \item \E has \textbf{pseudo-stable dependent products} if we have an operation assigning to each $A$ and $B$ a dependent product which is a type if $A$ and $B$ are, together with for any $\sigma:\Gamma'\to\Gamma$ and any cartesian liftings $\sigma_A: A' \to A$ over $\sigma$ and $\sigma_B: B'\to B$ over $\sigma.\sigma_A$, a cartesian arrow $\prod[A',B'] \to \prod[A,B]$ over $\sigma$, that is functorial and commutes with all the structure.
  \end{itemize}
\end{defn}

\begin{lem}\label{thm:categorical-pi}
  A weakly stable strong dependent product of $B$ along $A$ is precisely a pretype $\prod[A,B]$ such that $\chi(\prod[A,B]):\Gamma.\prod[A,B] \to \Gamma$ is a \emph{categorical} dependent product of $\chi(B)$ along $\chi(A)$, i.e.\ the value at $\chi(B)$ of a partially defined right adjoint to the pullback functor $\chi(A)^* : \E/\Gamma \to \E/\Gamma.A$.
\end{lem}
\begin{proof}
  If we unravel the definition of a weakly stable strong dependent product, we see that it says that for any $\sigma:\Delta\to\Gamma$, and any section $t:\Delta.A[\sigma] \to \Delta.A[\sigma].B[\sigma.\sigma_A]$, there is a unique section $\lambda(t) : \Delta \to \Delta.\prod[A,B][\sigma]$ such that
  \[ (\Delta.A[\sigma].\fapp_{A,B}[\sigma.\sigma_A]) \circ (1_{\Delta.A[\sigma]},\lambda(t) \circ \chi(A[\sigma])) = t. \]
  Now, by the universal property of pullbacks, such a $t$ is equivalent to a map $t':\Delta.A[\sigma] \to \Gamma.A.B$ such that $\chi(B) \circ t' = \sigma.\sigma_A$, and likewise $\lambda(t)$ is equivalent to a map $\lambda'(t'):\Delta \to \Gamma.\prod[A,B]$ such that
  \begin{equation}
    \Gamma.A.\fapp_{A,B} \circ {(\sigma.\sigma_A, \lambda'(t')\circ \chi(A[\sigma]))} = t'.\label{eq:wssdp}
  \end{equation}
  See below, where the left-hand side of~\eqref{eq:wssdp} is labeled $\bullet$.
  \begin{equation}
    \vcenter{\xymatrix{
        & \Gamma.A.B \ar[d]  &&
        \Gamma.A.\prod[A,B] \ar[dll] \ar[ll]_-{\Gamma.A.\fapp_{A,B}} \ar[d]^{\chi(A)_{\prod[A,B]}} \\
        \Delta.A[\sigma]\ar[r]_-{\sigma.\sigma_A}
        \ar@{.>}[urrr]^(.6){\bullet}
        \ar[d]_{\chi(A[\sigma])} \ar@{-->}[ur]^{t'} &
        \Gamma.A\ar[d] &&
        \Gamma.\prod[A,B] \ar[dll]^{\chi(\prod[A,B])} \\
        \Delta \ar[r]_\sigma \ar@{.>}[urrr]^(.6){\lambda'(t')} &
        \Gamma.
      }}
  \end{equation}
  Now noting that $\sigma$ is an arbitrary object of the slice category $\E/\Gamma$, and $\sigma.\sigma_A$ is its pullback along $\chi(A)$, this gives the desired conclusion.
\end{proof}

\begin{lem}
  If \E has weakly stable strong dependent products, then it has pseudo-stable strong dependent products.
\end{lem}
\begin{proof}
  It is a standard category-theoretic fact that categorical dependent products are preserved by pullback, up to canonical isomorphism.
  Thus, we can choose any family of weakly stable strong dependent products (choosing a type if $A$ and $B$ are types), and they will automatically be pseudo-stable.
\end{proof}

Now we consider $\sum$-types and the unit type.
\todo{If we do assume $\eta$, then I am tempted to formulate these negatively as well, in terms of projections.}

\begin{definition}
  Let \E be a HCC.
  \begin{itemize}
  \item Given a pretype $A$ in context $\Gamma$ and a pretype $B$ in context $\Gamma.A$, a \textbf{dependent sum} is a pretype $\sum_A B$ in context $\Gamma$ together with a pairing map $\pairing : \Gamma.A.B \to \Gamma.\sum_A B$, such that for any pretype $C$ in context $\Gamma.\sum_A B$ and section $d:\Gamma.A.B \to \Gamma.A.B.C[\pairing]$, there is a chosen section $\fsplit_{C,d} : \Gamma.\sum_A B \to \Gamma.\sum_A B.C$ such that $\fsplit_{C,d} \circ \pairing = (\pairing.C)\circ d$.
  \item A dependent sum is \textbf{strong} if the chosen sections are unique.
  % \item \E has \textbf{weakly stable dependent sums} if any $A$ and $B$ have a dependent sum such that for any $\sigma:\Delta\to\Gamma$, the pair $\sum_A B[\sigma]$ and $\pairing[\sigma]$ can be extended to a dependent sum as well, and moreover if $A$ and $B$ are types then their dependent sum can be chosen to be a type as well.
  \item \E has \textbf{strictly stable dependent sums} if we have an operation assigning to each $A$ and $B$ a dependent sum, which is a type if $A$ and $B$ are, such that all the data commutes strictly with pullback.
  \item \E has \textbf{pseudo-stable dependent sums} if \dots
  \end{itemize}
\end{definition}

\begin{definition}
  Let \E be a HCC.
  \begin{itemize}
  \item A \textbf{unit type} over context $\Gamma$ is a type $1$ with a section $\ftt : \Gamma \to \Gamma.1$ such that for any type $C$ in context $\Gamma.1$ and section $d$ of $C[\ftt]$, there is a chosen section of $C$ which composes with $\ftt$ to $d$.
  \item A unit type is \textbf{strong} if the chosen sections are unique.
  % \item \E has \textbf{weakly stable unit types} if each $\Gamma$ has a unit type such that for any $\sigma:\Delta\to\Gamma$, the pair $1[\sigma]$ and $\ftt[\sigma]$ can be extended to a unit type.
  \item \E has \textbf{strictly stable unit types} if we have an operation assigning to each context a unit type, such that all the data commutes strictly with pullback.
  \item \E has \textbf{pseudo-stable unit types} if \dots
  \end{itemize}
\end{definition}


\subsection{Pretype colimits}
\label{sec:pretype-colimits}

To formulate the rules for cofibrations, we need colimits of pretypes.
Specifically, we need pushouts, to be the domains of pushout products; but we also need a coproduct to be the domain of the canonical cofibration $2\to \Delta^1$.
Unlike in~\cite{vv:hts}, we do \emph{not} assume that coproducts of types are automatically types.
Indeed, it will follow, as a special case of our construction of HITs, that we can define a coproduct of types that is again a type, but because it requires a fibrant replacement, this coproduct type will no longer be able to eliminate into arbitrary pretypes.
Colimits of pretypes, however, are fairly easy to obtain in models.

We begin with coproducts.

\begin{defn}
  Let \E be a HCC.
  \begin{itemize}
  \item A \textbf{pretype binary sum} of pretypes $A_1$ and $A_2$ in context $\Gamma$ is a pretype $A_1+A_2$ in context $\Gamma$ with maps $\nu_i : \Gamma.A_i \to \Gamma.(A_1+A_2)$ over $\Gamma$, such that for any pretype $C$ in context $\Gamma.(A_1+A_2)$ with sections $t_i :\Gamma.A_i \to \Gamma.A_i.C[\nu_i]$, there is a chosen section $\Gamma.(A_1+A_2) \to \Gamma.(A_1+A_2).C$ that composes with each $\nu_i$ to $\nu_i.C \circ t_i$.
  \item A pretype binary sum is \textbf{strong} if the chosen sections are unique.
  \item \E has \textbf{weakly stable pretype binary sums} if for each $A_1$ and $A_2$ there is a pretype binary sum such that for each $\sigma:\Delta\to\Gamma$, $(A_1+A_2)[\sigma]$ with $\nu_i[\sigma]$ can be extended to a pretype binary sum.
  \item \E has \textbf{strictly stable pretype binary sums} if we have an operation assigning to each $A_1$ and $A_2$ a pretype binary sum, such that all the data commutes strictly with pullback.
  \item \E has \textbf{pseudo-stable pretype binary sums} if we have an operation assigning to each $A_1$ and $A_2$ a pretype binary sum, and to any $\sigma:\Delta\to \Gamma$ and any cartesian lifts $\sigma_{A_1}:A_1'\to A_1$ and $\sigma_{A_2}:A_2'\to A_2$, a cartesian arrow $A_1' + A_2' \to A_1+A_2$ over $\sigma$, commuting with the $\nu_i$ and the chosen sections.
  \end{itemize}
\end{defn}

Note that we do not ask for any interaction of the pretype binary sums with the fibration of types: the pretype sum of two types may no longer be a type.

\begin{lem}\label{thm:categorical-pretype-sums}
  Let \E be a HCC.
  \begin{enumerate}
  \item A strong pretype binary sum is a categorical coproduct in $\P(\Gamma)$.
  \item Conversely, any pretype in $\P(\Gamma)$ whose comprehension is a categorical coproduct in $\E$ yields a strong pretype binary sum.
  \item Any pretype in $\P(\Gamma)$ whose comprehension is a pullback-stable categorical coproduct in $\E$ yields a weakly stable pretype binary sum.
  \item If \E has weakly stable strong pretype binary sums, then it has pseudo-stable strong pretype binary sums.
  \end{enumerate}
\end{lem}
\begin{proof}
  For the first statement, any $B\in \P(\Gamma)$ can be reindexed to $B[\sigma_{A_1+A_2}] \in P(\Gamma.(A_1+A_2)$, so that maps $A_i \to B$ in $\P(\Gamma)$ correspond bijectively to sections $\Gamma.A_i \to \Gamma.A_i.B[\sigma_{A_1+A_2}][\nu_i]$, and similarly for maps out of $A_1+A_2$.
  Thus, the strong pretype binary sum property implies that any two maps $A_1\to B$ and $A_2\to B$ factor uniquely through $A_1+A_2$.

  Conversely, if we have a pretype $A_1+A_2 \in \P(\Gamma)$ such that $\Gamma.(A_1+A_2)$ is a categorical coproduct of $\Gamma.A_1$ and $\Gamma.A_2$, then since sections $t_i :\Gamma.A_i \to \Gamma.A_i.C[\nu_i]$ correspond bijectively to maps $\Gamma.A_i \to \Gamma.(A_1+A_2).C$ over $\Gamma.\nu_i$, they induce a unique section $\Gamma.(A_1+A_2) \to \Gamma.A_1+A_2.C$.

  The third and fourth statements follows immediately.
\end{proof}

Next we tackle pretype pushouts.
These are a sort of ``higher inductive pretype'', but instead of using identity types for the equalities, we use the judgmental equality, which semantically means the equality of morphisms in \E.
These were not considered in~\cite{lw:localuniv}, so we will be a little more careful.

\begin{defn}
  Let \E be a HCC.
  \begin{itemize}
  \item Given pretypes $A$, $B_1$, and $B_2$ in context $\Gamma$, and maps $\mu_i :\Gamma.A\to \Gamma.B_i$ over $\Gamma$, a \textbf{pretype pushout} of $\mu_1$ and $\mu_2$ consists of
    \begin{itemize}
    \item a pretype $B_1 +_A B_2$ in context $\Gamma$, and
    \item morphisms $\nu_i : \Gamma.B_i \to \Gamma.(B_1+_A B_2)$ over $\Gamma$ such that $\nu_1 \circ \mu_1 = \nu_2 \circ \mu_2$, such that
    \item for any pretype $C$ in context $\Gamma.(B_1 +_A B_2)$ with sections $t_i : \Gamma.B_i \to \Gamma.B_i.C[\nu_i]$ such that
      % \[\nu_1.(nu_1)_C \circ t_1 \circ \mu_1 = \nu_2.(\nu_2)_C \circ t_2\circ \mu_2,\]
      \[ (1_{\Gamma.A}, t_1\circ \mu_1) = (1_{\Gamma.A}, t_2\circ \mu_2) \]
      there is a chosen section $\fpush_{t_1,t_2}:\Gamma.(B_1 +_A B_2) \to \Gamma.(B_1 +_A B_2).C$ such that
      $(1_{\Gamma.B_i} , \fpush_{t_1,t_2} \circ \nu_i) = t_i$.
      % $\fpush_{t_1,t_2} \circ \nu_i = \nu_i.(\nu_i)_C \circ t_i$.
      \[ \xymatrix@-.5pc{
        \Gamma.A.C[\nu_i\mu_i] \ar[rr]^{\mu_2.(\mu_2)_C} \ar[dd] \ar[dr]_{\mu_1.(\mu_1)_C}  &&
        \Gamma.B_2.C[\nu_2] \ar'[d][dd] \ar[dr]^{\nu_2.(\nu_2)_C}\\
        & \Gamma.B_1.C[\nu_1] \ar[dd] \ar[rr]_(.6){\nu_1.(\nu_1)_C} &&
        \Gamma.(B_1+_A B_2).C\ar[dd]\\
        \Gamma.A \ar[dr]_{\mu_1} \ar'[r][rr]_{\mu_2} \ar@{-->}@(ul,dl)[uu]^{(1_{\Gamma.A}, t_i\circ \mu_i)} & &
        \Gamma.B_2 \ar[dr]^{\nu_2} \ar@{-->}@(ul,dl)[uu]^(.7){t_2}\\
        & \Gamma.B_1 \ar[rr]_{\nu_1} \ar@{-->}@(ul,dl)[uu]^(.7){t_1} &&
        \Gamma.(B_1+_A B_2) \ar@{.>}@(ur,dr)[uu]_{\fpush_{t_1,t_2}}
      }\]

    \end{itemize}
  \item A pretype pushout is \textbf{strong} if the chosen sections are unique.
  \item \E has \textbf{weakly stable pretype pushouts} if for each $A,B_i,\mu_i$ as above there is a pretype pushout such that for each $\sigma:\Delta\to\Gamma$, the data $(B_1 +_A B_2)[\sigma]$, and $\nu_i[\sigma]$ can be extended to a pretype pushout.
  \item \E has \textbf{strictly stable pretype pushouts} if we have an operation assigning to each $A,B_i,\mu_i$ a pretype pushout, such that for every $\sigma:\Delta\to\Gamma$,
    \begin{align*}
      (B_1 +_A B_2)[\sigma] &= B_1[\sigma] +_{A[\sigma]} B_2[\sigma]\\
      \nu_i[\sigma] &= \nu_i : B_i[\sigma] \to B_1[\sigma] +_{A[\sigma]} B_2[\sigma]\\
      \fpush_{t_1,t_2}[\sigma] &= \fpush_{t_1[\sigma],t_2[\sigma]}.
    \end{align*}
  \item \E has \textbf{pseudo-stable pretype pushouts} if we have an operation assigning to each $A,B_i,\mu_i$ a pretype pushout, together with for every $\sigma:\Gamma'\to\Gamma$ and cartesian liftings $\sigma_A:A'\to A$ and $\sigma_{B_i} : B_i' \to B_i$ (which induce unique maps $\mu_i' : A' \to B_i'$), a cartesian arrow $\sigma_{B_1} +_{\sigma_A} \sigma_{B_2} : B_1' +_{A'} B_2' \to B_1 +_A B_2$, such that
    \begin{align*}
      1_{B_1} +_{1_A} 1_{B_2} &= 1_{B_1 +_A B_2}\\
      (\tau_{B_1}\circ \sigma_{B_1}) +_{(\tau_A \circ \sigma_A)} (\tau_{B_2}\circ \sigma_{B_2})
      &= (\tau_{B_1} +_{\tau_A} \tau_{B_2}) \circ (\sigma_{B_1} +_{\sigma_A} \sigma_{B_2})\\
      (\sigma_{B_1} +_{\sigma_A} \sigma_{B_2}) \circ \nu_i' &= \nu_i' \circ \sigma_{B_i'}\\
      (\sigma.(\sigma_{B_1} +_{\sigma_A} \sigma_{B_2}))_C \circ \fpush_{t_1',t_2'} &= \fpush_{t_1,t_2} \circ (\sigma_{B_1} +_{\sigma_A} \sigma_{B_2})
    \end{align*}
    In the last equality, we have a pretype $C$ in context $\Gamma.(B_1 +_A B_2)$ so that $(\sigma.(\sigma_{B_1} +_{\sigma_A} \sigma_{B_2}))_C$ is a cartesian arrow $\Delta.C[\sigma.(\sigma_{B_1} +_{\sigma_A} \sigma_{B_2})] \to \Gamma.C$, and the sections $t_1$ and $t_2$ induce unique sections $t_1'$ and $t_2'$.
  \end{itemize}
\end{defn}

\begin{lem}\label{thm:categorical-pretype-pushouts}
  Let \E be a HCC.
  \begin{enumerate}
  \item A strong pretype pushout is a categorical pushout in $\P(\Gamma)$.
  \item Conversely, any pretype in $\P(\Gamma)$ whose comprehension is a categorical pushout in $\E$ yields a strong pretype pushout.
  \item Any pretype in $\P(\Gamma)$ whose comprehension is a pullback-stable categorical pushout in $\E$ yields a weakly stable pretype pushout.
  \item If \E has weakly stable strong pretype pushouts, then it has pseudo-stable strong pretype pushouts.
  \end{enumerate}
\end{lem}
\begin{proof}
  Just like \cref{thm:categorical-pretype-sums}.
\end{proof}


\subsection{Cofibrations and extensions}
\label{sec:semantic-cofibrations}

Recall that our hybrid comprehension categories come with a discrete fibration of ``cofibrations'' indexed by a ``source'' and ``target'' pretype in the same context.

\begin{definition}
  Let \E be a HCC with pseudo-stable pretype pushouts.
  We say that \E \textbf{has pushout products} if for any cofibrations $\cof{i_1}{A_1}{B_1}$ and $\cof{i_2}{A_2}{B_2}$ in context $\Gamma$, the map $i_1\pop i_2 : {(A_1 \times B_2) +_{A_1\times A_2} (B_1 \times A_2)} \to {B_1\times B_2}$ (induced by the elimination property of the pretype pushout) is a cofibration.
  \todo{If being a cofibration is structure (i.e.\ $\zeta$ is not injective), then this becomes an operation and needs stability.}
\end{definition}

Note that since cofibrations are closed under composing with isomorphisms, this condition is unchanged if we modify the pseudo-stable pushouts along isomorphisms.
We now move on to extension types.
To build familiarity, we start with a corresponding category-theoretic notion.

\begin{defn}\label{defn:extension-object}
  Let $A\xto{i} B \xto{p} \Gamma$ and $A\xto{c} C\xto{q} B$ be morphisms in a category with $q c = i$, and suppose that all pullbacks along $p$ and $pi$ exist.
  An \textbf{extension object} of $c$ along $i$ over $\Gamma$ is a morphism $\Ext(c,i)_\Gamma \to \Gamma$ such that for any morphism $x:X\to \Gamma$, lifts of $x$ to $\Ext(c,i)_\Gamma$ are in natural bijection with lifts of $p^*X \to B$ to $C$ whose composite with $(pi)^*X \to p^*X$ is equal to the composite $(pi)^*X \to A \xto{c} C$, i.e.\ dashed arrows as below that make the whole diagram commute:
  \[ \xymatrix{
    (pi)^*X \ar[r] \ar[d] & A \ar[d]_(.3)i \ar[r]^c & C \ar[dl]^q\\
    p^*X \ar[d] \ar[r] \ar@{-->}[urr] & B \ar[d]_(.3)p & \Ext(c,i)_\Gamma \ar[dl] \\
    X \ar[r]_x \ar@{.>}[urr] & \Gamma
    } \]
\end{defn}

\begin{lem}
  In the situation of \cref{defn:extension-object}, suppose the categorical dependent products $\Pi_p C$ and $\Pi_{pi} C$ exist.
  Then $\Ext(c,i)_\Gamma$ is the pullback
  \begin{equation}
    \vcenter{\xymatrix{
        \Ext(c,i)_\Gamma \ar[r]\ar[d] &
        \Pi_p C\ar[d]\\
        \Gamma \ar[r]_{\lambda(c)} &
        \Pi_{pi} C
      }}
  \end{equation}
  in the strong sense that if either exists, so does the other, and they are isomorphic.
\end{lem}
\begin{proof}
  Simply compare universal properties.
\end{proof}

\begin{cor}
  In a locally cartesian closed category, all extension objects exist.\qed
\end{cor}

We now move back to type theory.
Note that given an extension object as above, the Yoneda lemma furnishes us with a universal map $p^*\Ext(c,i)_\Gamma \to C$ over $B$, whose restriction to $(pi)^*\Ext(c,i)_\Gamma$ coincides with the composite $(pi)^*\Ext(c,i)_\Gamma \to A \xto{c} C$.
This corresponds closely to the type-theoretic formation and elimination.
As usual, the introduction and computation rules are formulated first in the special case when $X=\Gamma$, and then obtained over all $X$ by requiring stability.

\begin{defn}
  Let \E be a HCC, let $\cof{i}{A}{B}$ be a cofibration in context $\Gamma$, let $C$ be a type in context $\Gamma.B$, and let $c:\Gamma.A \to \Gamma.A.C[\Gamma.i]$ be a section.
  Note that $A$ and $B$ are only pretypes, but $C$ must be a type.\msnote{Should the fibrancy of $C$ and $\Ext$ be included in the definition, or should we allow extension pretypes as well and just assert separately that they preserve types?}
  An \textbf{extension type of $c$ along $i$} consists of:
  \begin{itemize}
  \item a type (not just a pretype) $\Ext_{C}(c,i)$ in context $\Gamma$,
  \item a map $\fapp_{i,c} : \Ext_C(c,i)[\chi(B)] \to C$ in context $\Gamma.B$, such that
  \item $\Gamma.A.\fapp_{i,c}[\Gamma.i] = c \circ \chi(\Ext_C(c,i)[\chi(B)][\Gamma.i])$ in context $\Gamma.A$, and
  \item for any section $t:\Gamma.B \to \Gamma.B.C$ such that
    \[(1_{\Gamma.A},t \circ \Gamma.i) = c\]
    (this is an equality of sections $\Gamma.A \to \Gamma.A.C[\Gamma.i]$) there is a chosen section $\lambda(t) : \Gamma \to \Gamma.\Ext_C(c,i)$ such that
    \[(\Gamma.B.\fapp_{i,c}) \circ (1_{\Gamma.B},\lambda(t) \circ \chi(B)) = t.\]
    (thish is an equality of sections $\Gamma.B \to \Gamma.B.C$).
  \end{itemize}
  An extension type is \textbf{strong} if the sections $\lambda(t)$ are unique.
\end{defn}

\begin{defn}
  Let \E be a HCC.
  \begin{itemize}
  \item An extension type $\Ext_C(c,i)$ as above is \textbf{weakly stable} for any $\sigma:\Delta\to\Gamma$, the type $\Ext_C(c,i)[\sigma]$ with $\fapp_{i,c}[\sigma]$ can be extended to an extension type of $c[\sigma]$ along $i[\sigma]$.
  \item \E has \textbf{strictly stable extension types} if we have an operation assigning to each $i$ and $c$ an extension type, such that all the data commutes strictly with pullback.
    In other words, we have
    \begin{align*}
      \Ext_C(c,i) &= \Ext_{C[\sigma]}(c[\sigma],i[\sigma])\\
      \fapp_{i,c}[\sigma] &= \fapp_{i[\sigma],c[\sigma]}\\
      \lambda(t)[\sigma] &= \lambda(t[\sigma])
    \end{align*}
  \item \E has \textbf{pseudo-stable extension types} if we have an operation assigning to each $i$ and $c$ an extension type, and to any $\sigma:\Gamma'\to\Gamma$ and any cartesian lifts $\sigma_A : A' \to A$ and $\sigma_B : B'\to B$ over $\sigma$, and $\sigma_C : C' \to C$ over $\sigma.\sigma_B$, a cartesian arrow $\Ext(\sigma_A,\sigma_B,\sigma_C) : \Ext_{C'}(c',i') \to \Ext_C(c,i)$ over $\sigma$, that is functorial and commutes with all the structure.
    Here $i':A'\to B'$ and $c':\Gamma'.A' \to \Gamma'.A'.C'[\Gamma'.i']$ are uniquely induced by the cartesian arrows $\sigma_A$ and $\sigma_B$, and $i'$ is a cofibration since cofibrations form a discrete fibration.
    Functoriality means
    \begin{align*}
      \Ext(1_A,1_B,1_C) &= 1_{\Ext(c,i)}\\
      \Ext(\tau_A \circ \sigma_A,\tau_B \circ \sigma_B,\tau_C \circ \sigma_C) &= \Ext(\tau_A,\tau_B,\tau_C) \circ \Ext(\sigma_A,\sigma_B,\sigma_C)
    \end{align*}
    and commuting with the structure means\msnote{I think $\Ext(\sigma_A,\sigma_B,\sigma_C)$ on the RHS of the $\fapp$ equation should be ``pulled back'' along $\chi(B)$ and $\chi(B')$.}
    \begin{align*}
      \sigma.\sigma_B.\sigma_C \circ \Gamma.B'.\fapp_{i',c'} &= \Gamma.B.\fapp_{i,c} \circ \sigma.\sigma_B.\Ext(\sigma_A,\sigma_B,\sigma_C)\\
      \sigma.\Ext(\sigma_A,\sigma_B,\sigma_C) \circ \lambda(t') &= \lambda(t) \circ \sigma
    \end{align*}
    where $t'$ is induced from $t$ in the obvious way.
  \end{itemize}
\end{defn}

\begin{lem}\label{thm:categorical-ext}
  A weakly stable strong extension type of $c$ along $i$ is precisely a type $\Ext_C(c,i)$ such that $\chi(\Ext_C(c,i)) : \Ext_C(c,i)\to \Gamma$ is a categorical extension object of $c$ along $\Gamma.i$ over $\Gamma$.
\end{lem}
\begin{proof}
  This is essentially just like \cref{thm:categorical-pi}.
  We rewrite the diagram in \cref{defn:extension-object} in semantic type theory language:
  \[ \xymatrix{
    \Delta.A[\sigma] \ar[r] \ar[d] & \Gamma.A \ar[d]_(.3)i \ar[r]^c & \Gamma.B.C \ar[dl]^q\\
    \Delta.B[\sigma] \ar[d] \ar[r] \ar@{-->}[urr] & \Gamma.B \ar[d]_(.3)p & \Gamma.\Ext(c,i)_\Gamma \ar[dl] \\
    \Delta \ar[r]_\sigma \ar@{.>}[urr] & \Gamma
  } \]
  and observe that this says precisely that $\Ext(c,i)[\sigma]$ is an extension type.
\end{proof}

\begin{lem}
  If \E has weakly stable strong extension types, then it has pseudo-stable strong extension types.
\end{lem}
\begin{proof}
  It is easy to show that categorical extension objects are stable under pullback.
\end{proof}

\subsection{Identity types and acyclics}
\label{sec:semantic-id-types}




\section{Model-categorical semantics}
\label{sec:model-categories}



\section{Overview of HIT syntax}
\label{sec:syntax}

Before beginning our consideration of examples, in this section we will give an overview of what the rules for HITs tend to look like.
This is \emph{not} a formal description, but serves only to orient the reader, so that in later sections when we do give formal descriptions their overall shape will not be a complete surprise.

\todo{Rewrite this section using dimension variables.}

\subsection{Specification of HITs}
\label{sec:hit-specs}

In this section we will use an informal Agda-like syntax for describing HITs.
For instance, the higher inductive circle $\circtype$ can be written as
\indef{\circtype}{
  \fbase : \circtype \OR
  \floop : \id[\circtype]{\fbase}{\fbase}
}
and the $(-1)$-truncation $\brck{A}$ can be written as
\indef{\brck{A}}{
  \fproj : A \to \brck{A} \OR
  \fsquash : \prd{x,y:\brck{A}} \id[\brck{A}]{x}{y}
}
while the torus $\torustype$ can be written as
\indef{\torustype}{
  \fbase : \torustype \OR
  \fmerid_1 : \id[\torustype]{\fbase}{\fbase} \OR
  \fmerid_2 : \id[\torustype]{\fbase}{\fbase} \OR
  \fsurf : \id[{\id[\torustype]{\fbase}{\fbase}}]{\fmerid_1 \ct \fmerid_2}{\fmerid_2 \ct \fmerid_1}
}
where $p\ct q$ denotes the concatenation of paths (i.e.\ the transitivity of equality).

In general, the \emph{domain} of a path-constructor is of the same form as the domain of a point-constructor: it must be a strictly positive functor of the type being defined.
The \emph{codomain} is some iterated path-type of the HIT being constructed.

Note that specifying the codomain of a path-constructor requires specifying terms belonging to the HIT being defined and perhaps also to its iterated path-spaces.
For instance, in $\circtype$ we must specify $\fbase$ and $\fbase$ to be the source and target of the path $\floop$; while in $\torustype$ we must specify $\fbase$ and $\fbase$, and then also ${\fmerid_1 \ct \fmerid_2}$ and ${\fmerid_2 \ct \fmerid_1}$, to give the source and target of $\fsurf$.
These terms will often refer to other point- and perhaps path-constructors, such as $\fbase$ and $\fmerid_1$ and $\fmerid_2$.

\subsection{Rules for HITs}
\label{sec:rules}

In general, every type forming operation in type theory comes with \emph{formation}, \emph{introduction}, \emph{elimination}, and \emph{computation} rules.
The above specifications of HITs give us the \textbf{formation} rules easily; in these simple cases, the formation rule is just ``such-and-such type exists'', e.g.
\[ \inferrule{ }{\circtype\type} \]
Formation rules become slighty more complicated when we allow parameters and indices.
For instance, the type $A$ in $\brck{A}$ is best treated as a parameter:
\indef{\brck{\blank} \; (A \type)}{
  \fproj : A \to \brck{A} \OR
  \fsquash : \prd{x,y:\brck{A}} \id[\brck{A}]{x}{y}
}
so that the formation rule becomes
\[ \inferrule{A\type}{\brck{A}\type} \]
However, no new ideas are introduced here by HITs as compared with ordinary inductive types.

The \textbf{introduction rules} for a HIT are also easy: they are just the specified constructors.
For instance, the introduction rules for $\circtype$ say that we have $\fbase:\circtype$ and also $\floop : \id[\circtype]\fbase\fbase$.
It is essential
\msnote{Do we need to say more about why this makes sense?}%
that we regard $\floop$ as an introduction rule for $\circtype$ itself, rather than for $\id[\circtype]\fbase\fbase$, even though it is actually an element of the latter type; this will become clear when we discuss the elimination and computation rules.
Indeed, the type family $\id[\circtype]{\blank}{\blank}$ already has its \emph{own} introduction rule, namely $\refl: \prd{x:\circtype} \id[\circtype]{x}{x}$.

It is when we get to the \textbf{elimination rules} that things get interesting.
Elimination for ordinary inductive types can be specified either with an \emph{induction principle} or with \emph{pattern matching}.
From the perspective of categorical semantics, it appears necessary to regard the induction principle as basic, with pattern matching justified (insofar as possible) by reduction to the induction principle, as in~\cite{gmm:pattern-matching,cdp:without-k}.
It is not yet clear what a general formulation of pattern matching for HITs would look like (although cubical type theory makes it seem more likely to be possible).
Thus, in this paper we will concentrate on induction principles.

For an ordinary inductive type $W$, the induction principle says that for any type family $B$ over $W$, if we have operations on $B$ that correspond to, and ``live over'', each constructor of $W$, then we can define a function $f:\prd{x:W}B(x)$.
For instance, the induction principle for \lN says that if we have a type family $B$ over \lN equipped with $f_\fzero : B(\fzero)$ and $f_\fsucc : \prd{n:\lN} B(n) \to B(\fsucc(n))$, then we are entitled to a function $\ind{\lN}(B,f_\fzero,f_\fsucc):\prd{n:\lN} B(n)$.
We expect the induction principle for a HIT to be similar; the only question is what sort of operations on $B$ should be required to correspond to the path-constructors.
This is the role of the \emph{dependent path} type introduced in \cref{sec:syntactic-type-theory}.

Consider, for example, the interval:
\indef{I}{
  \fzero : I \OR
  \fone : I \OR
  \fseg : \id[I]{\fzero}{\fone}
}
We expect the premises of its induction principle to include $f_\fzero : B(\fzero)$ and $f_\fone : B(\fone)$; but then corresponding to \fseg, we would expect some sort of path relating $f_\fzero$ to $f_\fone$.
We cannot even form a type ``$\id{f_\fzero}{f_\fone}$'' since $f_\fzero$ to $f_\fone$ have different types, but we \emph{can} ask for a dependent path $f_\fseg : \idover[B]{f_\fzero}{f_\fone}{\fseg}$.
Thus, the entire elimination rule for $I$ is
\[\inferrule{\jd{x:I |- B(x) \type} \\ f_\fzero : B(\fzero) \\ f_\fone : B(\fone) \\ f_\fseg : \idover[B]{f_\fzero}{f_\fone}{\fseg}}{\jd{x:I |- \ind{I}(B,f_\fzero,f_\fone,f_\fseg)(x) : B(x)}} \]

The general principle is thus that path-constructors in a HIT correspond to dependent path premises in its induction principle.
For instance, the circle $\circtype$ has the following elimination rule:
\[\inferrule{\jd{x:\circtype |- B(x) \type} \\ f_\fbase : B(\fbase) \\ f_\floop : \idover[B]{f_\fbase}{f_\fbase}{\floop}}{\jd{x:\circtype |- \ind{\circtype}(B,f_\fbase,f_\floop)(x) : B(x)}} \]
Note that in this case it would be possible to \emph{write} the non-dependent path type ``$\id[B(\fbase)]{f_\fbase}{f_\fbase}$'', but that this is \emph{not} the correct type for $f_\floop$.

Path-constructors with nontrivial domain are handled in the expected way, by dependent functions outputting dependent paths.
For instance, the \textbf{suspension} of a type $A$ is defined by
\indef{\susp A}{
  \fnorth : \susp A \OR
  \fsouth : \susp A \OR
  \fmerid : \prd{x:A} \id[\susp A]{\fnorth}{\fsouth}
}
Its induction principle is
\[\inferrule{\jd{x:\susp A |- B(x) \type} \\ f_\fnorth : B(\fnorth) \\ f_\fsouth : B(\fsouth) \\ f_\fmerid : \tprd{x:A} \idover[B]{f_\fnorth}{f_\fsouth}{\fmerid(x)}}
{\jd{x:\susp A |- \ind{\susp A}(B,f_\fnorth,f_\fsouth,f_\fmerid)(x):B(x)}} \]
Similarly, path-constructors with recursive inputs correspond to inductive premises that take inputs from the induction motive.
For instance, the induction principle for the $(-1)$-truncation $\brck{A}$ is
\[\inferrule{\jd{x:\brck A |- B(x) \type} \\ f_\fproj : \tprd{a:A} B(\fproj(a)) \\ f_\fsquash : \tprd{x,y:\brck A}{u:B(x)}{v:B(y)} \idover[B]{u}{v}{\fsquash(x,y)}}
{\jd{x:\brck A |- \ind{\brck A}(B,f_\fproj,f_\fsquash)(x) : B(x)}}
\]
This should be compared with the familiar induction principle for the natural numbers:
\[ \inferrule{\jd{x:\lN |- B(x) \type} \\ f_\fzero : B(\fzero) \\ f_\fsucc : \tprd{x:\lN}{u:B(x)} B(\fsucc(x))}
{\jd{x:\lN |- \ind{\lN}(B,f_\fzero,f_\fsucc)(x) : B(x)}}
\]
In both cases, each recursive argument to a constructor ($\fsucc$ or $\fsquash$) bifurcates into two arguments to the corresponding induction premise, one from the inductive type being defined and one from the induction motive.

For HITs with higher-dimensional path-constructors, such as the 2-sphere and the torus, we require a corresponding notion of higher dependent path.
\msnote{Should probably define that and be precise here.}

Finally, \textbf{computation rules} say that when a function defined by elimination is applied to a form obtained by introduction, the result reduces using the inputs of the elimination.
For example, if $f:\lN \to B$ is defined by recursion from $f_\fzero : B$ and $f_\fsucc : B \to B$, then we have $f(\fzero) \jdeq f_\fzero$ and $f(\fsucc(x)) \jdeq f_\fsucc(f(x))$.

To state similar rules for the path-constructors of HITs, we need the operation $\ap_f$.
For instance, the if $f:\circtype \to B$ is defined from $f_\fbase:B$ and $f_\floop : \id[B]{f_\fbase}{f_\fbase}$, we should have $f(\fbase) \jdeq f_\fbase$ (of course) and $\ap_{f}(\floop) \jdeq f_\floop$.
Note that $\ap_{f}(\floop)$ and $f_\floop$ are both elements of $\id[B]{f_\fbase}{f_\fbase}$, the latter by definition and the former because of the first computation rule.
When $B$ depends on $\circtype$, we need the dependent extension of $\ap_f$ which was discussed in \cref{sec:cubic-ident-types}.
The precise rules are
\[ \inferrule{\jd{x:\circtype |- B(x) \type} \\ f_\fbase : B(\fbase) \\ f_\floop : \idover[B]{f_\fbase}{f_\fbase}{\floop}}{\ind{\circtype}(B,f_\fbase,f_\floop)(\fbase)\jdeq f_\fbase \\ \ap_{\ind{\circtype}(B,f_\fbase,f_\floop)}(\floop) \jdeq f_\floop} \]
Similarly, for the suspension we have
\[\inferrule{\jd{x:\susp A |- B(x) \type} \\ f_\fnorth : B(\fnorth) \\ f_\fsouth : B(\fsouth) \\ f_\fmerid : \tprd{x:A} \idover[B]{f_\fnorth}{f_\fsouth}{\fmerid(x)}}
{\ind{\susp A}(B,f_\fnorth,f_\fsouth,f_\fmerid)(\fnorth) \jdeq f_\fnorth \\
  \ind{\susp A}(B,f_\fnorth,f_\fsouth,f_\fmerid)(\fsouth) \jdeq f_\fsouth \\
  \jd{x:A |- \ap_{\ind{\susp A}(B,f_\fnorth,f_\fsouth,f_\fmerid)}(\fmerid(x)) \jdeq f_\fmerid(x)}} \]
As for ordinary inductive types, in the computation rules for path-constructors with recursive inputs, the right-hand side involves a recursive call to the function defined by induction.
For instance, the computation rules for $\brck{A}$ are
\[\inferrule{\jd{x:\brck A |- B(x) \type} \\ f_\fproj : \tprd{a:A} B(\fproj(a)) \\ f_\fsquash : \tprd{x,y:\brck A}{u:B(x)}{v:B(y)} \idover[B]{u}{v}{\fsquash(x,y)}}
{\jd{a:A |- \ind{\brck A}(B,f_\fproj,f_\fsquash)(\fproj(a)) \jdeq f_\fproj(a)}\\
\jd{x:\brck A , y:\brck A |- \ap_f(\fsquash(x,y)) \jdeq f_\fsquash(x,y,f(x),f(y))}}
\]
(In the last rule we have abbreviated $\ind{\brck A}(B,f_\fproj,f_\fsquash)$ by $f$ for readability.)



\subsection{Judgmental vs propositional computation rules}
\label{sec:comprules}

Note that all of our computation rules are judgmental, even those involving path-constructors and $\ap$.
This is very convenient for applications, and it is what we will get from our semantic construction as well.
It does depend crucially on the fact that we state these rules using the cubical $\ap$ defined by abstraction over lines, rather than the version $\ap'$ defined using the eliminator for identity types: as far as we know the computation rules do \emph{not} hold judgmentally in our models for $\ap'$.
However, as remarked in \cref{sec:cubic-ident-types}, we do have a propositional equality
\[ \jd{a_0:A , a_1:A, p:\id[A]{a_0}{a_1} |- \fapeq(p) : \id[{\id[B]{f(a_0)}{f(a_1)}}]{\ap'_f(p)}{\ap_f(p)}}. \]
Together with our judgmental computation rules for $\ap$, this implies that \emph{propositional} computation rules hold for $\ap'$.
For instance, given a type $B$ with $f_\fbase$ and $f_\floop : \id[B]{f_\fbase}{f_\fbase}$, if we write $f$ for ${\ind{\circtype}(B,f_\fbase,f_\floop)}$, then we have as above 
\[ \ap_f(\floop) \jdeq f_\floop \]
and therefore 
\[ \fapeq(\floop) : \id[B]{\ap'_f(\floop)}{f_\floop} \]
Thus, in MLTT regarded as a fragment of our type theory, we have HITs with judgmental computation rules for point-constructors and propositional computation rules for path-constructors.
Most work with HITs so far has used propositional computation rules of this form for path-constructors (with the defined $\ap'$).
One reason for this is that if we want to use $\ap'$ (since the cubical $\ap$ is not available in existing proof assistants), then such propositional rules are all we can get out of our semantics in general.
Another, perhaps more compelling, reason is while that existing proof assistants do not implement HITs natively, there is a hack using ``private types'' due to Licata~\cite{licata:private-types} which enables them to be mimicked, but only with propositional computation rules for path-constructors.

Judgmental computation rules for \emph{point}-constructors are unproblematic from any perspective: they don't require choosing between $\ap$ and $\ap'$, they do hold in the semantics, and they can be implemented in proof assistants using the private-types hack.

Note also that the (judgmental!) computation rules for point-constructors are necessary in order for the computation rules for path-constructors to be well-typed.
For example, by definition we have
\begin{align}
  \ap_{\ind{I}(f_\fzero,f_\fone,f_\fseg)}(\fseg) &:
  \idover{\ind{I}(f_\fzero,f_\fone,f_\fseg,\fzero)}{\ind{I}(f_\fzero,f_\fone,f_\fseg,\fone)}{\fseg}\\
  f_\fseg &: \idover{f_\fzero}{f_\fone}{\fseg}.
\end{align}
Only the computation rules for $\fzero$ and $\fone$ ensure that these two types coincide, so that it makes sense to ask whether $\ap_{\ind{I}(f_\fzero,f_\fone,f_\fseg)}(\fseg)$ and $f_\fseg$ are equal.
If we had only propositional computation rules such as
\begin{align}
  \fcomp_\fzero &: \id{\ind{I}(f_\fzero,f_\fone,f_\fseg,\fzero)}{f_\fzero}\\
  \fcomp_\fone &: \id{\ind{I}(f_\fzero,f_\fone,f_\fseg,\fone)}{f_\fone}
\end{align}
then in order for the computation rule of \fseg to make sense, we would need to transport along (or, equivalently, compose with) these paths; thus we could at best ask for
\[ \fcomp_\fseg :
\id{\opp{\fcomp_\fzero}\ct \ap_{\ind{I}(f_\fzero,f_\fone,f_\fseg)}(\fseg) \ct \fcomp_\fone}{f_\fseg}
\]
Such modifications quickly become quite tedious, so it is fortunate that judgmental computation rules for point-constructors are unproblematic.
However, when considering \emph{higher} path-constructors---or more generally, path-constructors whose source and target refer to previous path-constructors---if we are restricted to propositional computation rules for the previous path-constructors, then there is no escape.
Such a translation should in principle always be possible, but we will not attempt to describe it in general; we expect it would probably not be worth the effort, since the presence of all these adjusting paths makes HITs with higher path-constructors barely usable in plain MLTT.

It should be noted, though, that one can do quite a lot using only 1-dimensional paths.
For instance, a type equivalent to $\spheretype{2}$ can be defined as $\susp \circtype$, and more generally an $n$-sphere $\spheretype{n}$ can be obtained by iterated suspension.
One can even argue that \emph{all} higher-dimensional path-constructors are reducible to 1-dimensional ones, as in~\cite{lumsdaine:hub-and-spoke} --- although this reduction does not preserve judgmentality of the computation rules, and moreover it uses path-constructors whose domains and codomains are more general than those that we currently know how to deal with in our semantics (specifically, they involve the eliminators for other HITs).


\section{The circle}
\label{sec:circtype}

\todo{Reorganize along general lines}

As we did for inductive types above, to model the circle we first set up a (fibered) category of “algebras”, with a notion of “fibration”, and observe that a stably trivially cofibrant object in this category will model the rules for the circle.
%
In the case of the circle, it is then easy to construct such an object by hand.

\begin{definition}
A \emph{fibrant circle algebra} over $\Gamma \in \E$ is a fibration $X \fibto \Gamma$ equipped with a section $b : \Gamma \to X$, and a map $l : \Gamma \to \paths[\Gamma]{X}$ over $(b,b) : \Gamma \to X \times_\Gamma X$.
%
If $(X,b,l)$ is a fibrant circle algebra over $\Gamma$, then any $f : \Gamma' \to \Gamma$ induces a pullback fibrant circle algebra $f^*(X,b,l) := (f^*X,f^*b,f^*l)$ over $\Gamma'$.
\end{definition}

The formation and introduction rules say exactly that the circle $\circtype$ is a fibrant circle algebra over $1$.

\begin{definition}
A \emph{dependent circle algebra} over a fibrant circle algebra $(X,b,l)$ over $\Gamma$ consists of a fibration $Y \fibto X$, equipped with a map $\bbar : \Gamma \to Y$ over $b$, and a map $\lbar : \Gamma \to \pathsover[\Gamma]{X}{Y}$ over $(\bbar,l,\bbar) : \Gamma \to Y \times_X \paths[\Gamma]{X} \times_X Y$. 
\end{definition}

The premises of the elimination and computation rules, in context $\Gamma$, posit precisely a dependent circle algebra over the pullback of $\circtype$ along $\Gamma \to 1$.

\begin{definition}
A \emph{(strict) section} of a dependent circle algebra $(Y,\bbar,\lbar)$ over $(X,b,l)$, $\Gamma$ is a section $s$ of the fibration $Y \fibto X$, such that $s(b) = \bbar$, $\paths[\Gamma]{s}(l) = \lbar$.

If $Y = (Y,\bbar,\lbar)$ is a dependent circle algebra over $X = (X,b,l)$, in context $\Gamma$, then pulling back along $f : \Gamma' \to \Gamma$ induces a dependent circle algebra $f^*Y$ over $f^*X$.
\end{definition}

The eliminator, together with the (judgemental) computation rules, provide a section for every dependent circle algebra over any pullback of  $\circtype$, along with stability conditions, which we disregard for now but will return to in Lemma~\ref{lemma:circle-coherence} below.
%
Based on this, we define:
\begin{definition}
A fibrant circle algebra is \emph{trivially cofibrant} if every dependent circle algebra over it has a section, and \emph{stably trivially cofibrant} if every pullback of it is trivially cofibrant.
\end{definition}

So far, we have set up these definitions following the syntactic presentation as closely as possible, and not relying on any features particular to the model-categorical setting.
%
However, in this setting---in particular, with strict functoriality of $\paths{-}$---these fit into a rather cleaner big picture:

\begin{definition}
There is an $\E$-indexed category $\Alg[\E]{\circtype}$, with an $\E$-indexed forgetful functor $U : \Alg[\E]{\circtype} \to \Eself$.

Objects of $\Alg[\E]{\circtype}$ consist of triples $(p:X \to \Gamma,b,l)$, as before, but with $p$ not assumed to be a fibration.
%
Maps of $(X',b',l') \to (X,b,l)$ in $\Alg[\E]{\circtype}(\Gamma)$ consist of maps $f : X' \to X$ over $\Gamma$, with $f(b') = b$, $\paths[\Gamma]{f}(l') = l$.

The functor $U$ sends a circle algebra $(X,b,l)$ over $\Gamma$ to its underlying map $p:X \to \Gamma$.

Moreover, $U$ induces an indexed subcategory of \emph{fibrations} in $\Alg[\E]{\circtype}$. 
\end{definition}

With this setting, a fibrant circle algebra over $\Gamma$, as originally defined, is exactly a fibrant object of $\Alg[\E]{\circtype}(\Gamma)$; a dependent circle algebra over $(X,b,l)$ is just a fibration over $(X,b,l)$ in $\Alg[\E]{\circtype}$; and a section of one is exactly a section in the usual sense.

\todo{Construct stable initial algebra as pushout; then, stably triv cof alg as fibrant replacement.}

\todo{State local universes lemma: “weakly stable triv cof alg in $\E$ gives strictly stable circle type in $\E_!$”.}

\section{Suspension}
\label{sec:susp}



\section{The torus}
\label{sec:torustype}

\todo{Leftovers here}

When we move on to higher-dimensional HITs, the elimination and computation rules start to involve the requirement of \emph{naturality} that we briefly mentioned before.
Consider the torus type $\torustype$, whose induction principle looks like this:
\[ \inferrule{\jd{x:\torustype |- B(x)\type}\\f_\fbase : B(\fbase) \\
  f_{\fmerid_1} : \idover[B]{f_\fbase}{f_\fbase}{\fmerid_1} \\
  f_{\fmerid_2} : \idover[B]{f_\fbase}{f_\fbase}{\fmerid_2} \\
  f_\fsurf : \idover[{\idover[B]{f_\fbase}{f_\fbase}{\blank}}]{f_{\fmerid_1} \ct f_{\fmerid_2}}{f_{\fmerid_2} \ct f_{\fmerid_1}}{\fsurf}}
{\jd{x:\torustype |- \ind{\torustype}(f_\fbase,f_{\fmerid_1},f_{\fmerid_2},f_\fsurf,x):B(x)}}
\]
Note the type of $f_\fsurf$.
It is a dependent path relative to the type family
\[\jd{p:\id[\torustype]{\fbase}{\fbase} |- {\idover[B]{f_\fbase}{f_\fbase}{p}}\type}\]
between
\begin{align}
  {f_{\fmerid_1} \ct f_{\fmerid_2}} &: \idover[B]{f_\fbase}{f_\fbase}{\fmerid_1\ct\fmerid_2} \qquad\text{and}\\
  {f_{\fmerid_2} \ct f_{\fmerid_1}} &: \idover[B]{f_\fbase}{f_\fbase}{\fmerid_2\ct\fmerid_1}
\end{align}
that lies over
\[\fsurf : \id[\torustype]{\fmerid_1\ct\fmerid_2}{\fmerid_2\ct\fmerid_1}.\]
But what does ``${f_{\fmerid_1} \ct f_{\fmerid_2}}$'' mean?
We need a way to ``compose'' dependent paths $q_1: \idover[B]x y {p_1}$ and $q_2:\idover[B]yz{p_2}$ to get a path $q_1\ct q_2 : \idover[B]{x}{z}{p_1\ct p_2}$.
Such an operation is easy to define (with any definition of dependent paths), but this ``liftability to families'' is a special property of path-concatenation.
As we will see when we construct semantics, it is a sort of \emph{naturality}.

For this reason, we cannot allow just any term to appear as the source or target of a path-constructor; a specific example is given in~\cite[Example 6.13.1]{hottbook} of an attempted ``higher inductive type'' for which it seems impossible to write down an induction principle.
Unfortunately, we do not yet know a \emph{syntactic} criterion on such terms which ensures the requisite naturality and includes all desired examples.

The computation rules for $\torustype$ also involve special properties of path-concatenation, and also some apparently unavoidable propositional equalities.
As in the previous cases, we have
\begin{align}
  \ind{\torustype}(f_\fbase,f_{\fmerid_1},f_{\fmerid_2},f_\fsurf,\fbase) &\jdeq f_\fbase\\
  \ap_{\ind{\torustype}(f_\fbase,f_{\fmerid_1},f_{\fmerid_2},f_\fsurf)}(\fmerid_1) &\jdeq f_{\fmerid_1}\\
  \ap_{\ind{\torustype}(f_\fbase,f_{\fmerid_1},f_{\fmerid_2},f_\fsurf)}(\fmerid_2) &\jdeq f_{\fmerid_2}
\end{align}
but what about \fsurf?
Writing $f$ for $\ind{\torustype}(f_\fbase,f_{\fmerid_1},f_{\fmerid_2},f_\fsurf)$, we have
\begin{align}
  \ap_{\ap_{f}}(\fsurf)
  &: \idover[{\idover[B]{f_\fbase}{f_\fbase}{\blank}}]{\ap_{f}(\fmerid_1 \ct \fmerid_2)}{\ap_{f}(\fmerid_2 \ct \fmerid_1)}{\fsurf}\\
  f_\fsurf &: \idover[{\idover[B]{f_\fbase}{f_\fbase}{\blank}}]{f_{\fmerid_1} \ct f_{\fmerid_2}}{f_{\fmerid_2} \ct f_{\fmerid_1}}{\fsurf}
\end{align}
However, while we have $\ap_{f} (\fmerid_1) \jdeq f_{\fmerid_1}$ and $\ap_{f} (\fmerid_2) \jdeq f_{\fmerid_2}$ by the previous computation rules, we do not have ${\ap_{f}(\fmerid_1 \ct \fmerid_2)}$ judgmentally equal to $\ap_{f} (\fmerid_1) \ct \ap_{f} (\fmerid_2)$.
The most we can say is that there is a \emph{propositional} equality
\[ \fap_{\ct} : \id[{\idover[B]{f_\fbase}{f_\fbase}{\fmerid_1 \ct \fmerid_2}}]{\ap_{f}(\fmerid_1 \ct \fmerid_2)}{\ap_{f} (\fmerid_1) \ct \ap_{f} (\fmerid_2)}. \]
(This equality is another expression of the \emph{naturality} of path-concatenation, but this time it is only a \emph{propositional} or \emph{pseudo} naturality.)
Thus, the best we can do for a computation rule for $\fsurf$ is an equality
\begin{equation}
  \fcomp_{\fsurf}: \id{\opp{\fap_{\ct}} \ct \ap_{\ap_{f}}(\fsurf) \ct \fap_{\ct}}
  {f_\fsurf}.\label{eq:fsurf-comp}
\end{equation}
It doesn't make sense to ask for this as a \emph{judgmental} equality, even though the computation rules for $\fmerid_1$ and $\fmerid_2$ are judgmental, because the equality $\fap_{\ct}$ is defined using the elimination principle for identity types and we have little control over its judgmental behavior.
In particular, the equality~\eqref{eq:fsurf-comp} will not generally hold judgmentally in our semantics.

By analogy with our introduction of the primitive \fap, one way to avoid this issue would be to assert that the primitive \fap preserves concatenation judgmentally, i.e.\ that we have $\ap_{f}(p\ct q) \jdeq \ap_{f}(p) \ct \ap_{f}(q)$.
Unfortunately, this is not true in most known semantics (with the \mswarning*{Make sure that's true}{notable exception} of the 1-groupoid model~\cite{hs:gpd-typethy}).

In our construction of semantics, we will see that there turns out to be a sort of partially defined ``primitive path-concatenation'' that is propositionally equal to the usual one, and which is preserved judgmentally by the primitive $\ap_{f}$ \emph{when $f$ is defined by induction} (but not for all $f$).
This will be what enables us to construct the \emph{propositional} equality~\eqref{eq:fsurf-comp}, just as the judgmental rules for primitive \fap enable the deduction of propositional rules for the defined $\ap'$.
However, this more complicated structure is tricky and probably unhelpful to represent syntactically.
\msnote{Actually, that may be closely like what cubical type theory is doing\dots}

In short, although our method of constructing semantics works in simple cases, and ought to work in all cases in principle, the resulting rules for more complicated and higher-dimensional HITs contain proliferating propositional equalities that are tedious and difficult to write down and work with.
We do not yet have a satisfactory solution to this problem; which is not hugely surprising as it is closely related to the coherence problem for weak $\infty$-categories.


\section{Propositional truncation}
\label{sec:brck}


\section{Some non-examples}
\label{sec:loopy}


\section{Simple higher $W$-types}
\label{sec:twoconstr-hwt}


\section{Higher $W$-types}
\label{sec:hwt}


\bibliographystyle{alpha}
\bibliography{basictex/all}

\end{document}
